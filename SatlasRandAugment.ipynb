{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90819b9f-8761-4d9f-9f1d-85498dbb0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sImports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import LightningModule, Trainerss\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, JaccardIndex\n",
    "from torchmetrics.collections import MetricCollection\n",
    "import torchvision.transforms.functional as TF \n",
    "import random\n",
    "import satlaspretrain_models # Using the allenai library\n",
    "import rasterio\n",
    "import glob\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "BASE_DATA_DIR_ACTUAL = \"<BASE_DATA_DIR>\"\n",
    "CHECKPOINT_SAVE_DIR_ACTUAL = \"<CHECKPOINT_SAVE_DIR>\"\n",
    "LOGS_DIR_ACTUAL = \"<LOGS_DIR>\"\n",
    "PATCHES_DIR = os.path.join(BASE_DATA_DIR_ACTUAL, \"GEE_WeeklyPatches\")\n",
    "TARGETS_DIR = os.path.join(BASE_DATA_DIR_ACTUAL, \"GEE_WeeklyMasks\")\n",
    "\n",
    "os.makedirs(CHECKPOINT_SAVE_DIR_ACTUAL, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR_ACTUAL, exist_ok=True)\n",
    "\n",
    "print(f\"Data Dir: {BASE_DATA_DIR_ACTUAL}\")\n",
    "print(f\"Checkpoints Dir: {CHECKPOINT_SAVE_DIR_ACTUAL}\")\n",
    "print(f\"Logs Dir: {LOGS_DIR_ACTUAL}\")\n",
    "print(f\"INFO: allenai/satlaspretrain_models will use its default cache path (usually ~/.cache/torch/hub/satlaspretrain/)\")\n",
    "\n",
    "if not os.path.isdir(PATCHES_DIR): print(f\"WARNING: Patches directory not found: {PATCHES_DIR}\")\n",
    "if not os.path.isdir(TARGETS_DIR): print(f\"WARNING: Masks directory not found: {TARGETS_DIR}\")\n",
    "\n",
    "# ============ MODEL CONFIG (allenai/satlaspretrain_models) ============ #\n",
    "SATLAS_MODEL_IDENTIFIER = \"Sentinel2_SwinB_SI_MS\"\n",
    "\n",
    "RAW_BANDS_IN_GEOTIFF_ORDER = ['B2','B3','B4','B8','B11','B12']\n",
    "NUM_RAW_BANDS_AVAILABLE = len(RAW_BANDS_IN_GEOTIFF_ORDER)\n",
    "RAW_BAND_TO_IDX_MAP = {band_name: i for i, band_name in enumerate(RAW_BANDS_IN_GEOTIFF_ORDER)}\n",
    "\n",
    "SATLAS_INPUT_CHANNEL_NAMES = [\n",
    "    \"TCI_R\", \"TCI_G\", \"TCI_B\",\n",
    "    \"B05_duplicate\", \"B06_duplicate\", \"B07_duplicate\",\n",
    "    \"B08_from_B8\", \"B11\", \"B12\"\n",
    "]\n",
    "NUM_SATLAS_INPUT_BANDS = len(SATLAS_INPUT_CHANNEL_NAMES)\n",
    "\n",
    "SATLAS_CHANNEL_TO_SOURCE_RAW_BAND_MAP = {\n",
    "    \"TCI_R\": \"B4\", \"TCI_G\": \"B3\", \"TCI_B\": \"B2\",\n",
    "    \"B05_duplicate\": \"B4\", \"B06_duplicate\": \"B3\", \"B07_duplicate\": \"B2\",\n",
    "    \"B08_from_B8\": \"B8\", \"B11\": \"B11\", \"B12\": \"B12\"\n",
    "}\n",
    "NORMALIZATION_DIVISOR = 8160.0\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# ============ TRAINING HYPERPARAMETERS & OTHER CONFIGS ============ #\n",
    "BATCH_SIZE = 2; EPOCHS = 100; LR = 1e-5; WEIGHT_DECAY = 0.01\n",
    "FREEZE_BACKBONE_FPN = False\n",
    "\n",
    "# --- RANDOMAUGMENT STYLE CONFIG ---\n",
    "APPLY_AUGMENTATIONS_TRAIN_SET = True\n",
    "NUM_RAND_AUGMENT_OPS = 2  # N: Number of distinct augmentations to pick from the pool and apply\n",
    "\n",
    "# Enable specific augmentations to be part of the pool and their parameters\n",
    "RAND_AUG_H_FLIP_ENABLE = True\n",
    "\n",
    "RAND_AUG_V_FLIP_ENABLE = True\n",
    "\n",
    "RAND_AUG_ROTATION_ENABLE = True\n",
    "RAND_AUG_ROTATION_DEGREES_OPTIONS = [0, 90, 180, 270] # Discrete angles if rotation is chosen\n",
    "\n",
    "RAND_AUG_BRIGHTNESS_ENABLE = True\n",
    "RAND_AUG_BRIGHTNESS_RANGE = (0.75, 1.25) # Factor range for brightness adjustment\n",
    "\n",
    "RAND_AUG_CONTRAST_ENABLE = True\n",
    "RAND_AUG_CONTRAST_RANGE = (0.75, 1.25)   # Factor range for contrast adjustment\n",
    "\n",
    "RAND_AUG_GAMMA_ENABLE = True\n",
    "RAND_AUG_GAMMA_RANGE = (0.8, 1.2)      # Gamma value range\n",
    "\n",
    "RAND_AUG_GAUSSIAN_NOISE_ENABLE = True\n",
    "RAND_AUG_GAUSSIAN_NOISE_STD = 0.03     # Standard deviation for Gaussian noise\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 15; EARLY_STOPPING_MONITOR = \"val_loss\"\n",
    "\n",
    "# DEVICE determination (simple check)\n",
    "USE_CUDA_IF_AVAILABLE = True\n",
    "if USE_CUDA_IF_AVAILABLE and torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(f\"Device selected: {DEVICE} (CUDA available: {torch.cuda.is_available()})\")\n",
    "\n",
    "for name in SATLAS_INPUT_CHANNEL_NAMES:\n",
    "    source = SATLAS_CHANNEL_TO_SOURCE_RAW_BAND_MAP.get(name)\n",
    "    if not source or source not in RAW_BAND_TO_IDX_MAP:\n",
    "        print(f\"CRITICAL WARNING: Source band for Satlas channel '{name}' ('{source}') is not valid. Check config.\")\n",
    "if NUM_SATLAS_INPUT_BANDS != 9: print(f\"CRITICAL WARNING: NUM_SATLAS_INPUT_BANDS is {NUM_SATLAS_INPUT_BANDS}, Satlas MS expects 9.\")\n",
    "\n",
    "class CerealSensingDataset(Dataset):\n",
    "    def __init__(self, file_identifiers, patches_dir, targets_dir, target_img_size,\n",
    "                 raw_band_to_idx_map, satlas_input_channel_names,\n",
    "                 satlas_channel_to_source_raw_band_map, normalization_divisor,\n",
    "                 augmentations=False, # General switch for applying augmentations\n",
    "                 num_rand_augment_ops=0,\n",
    "                 # Flags and parameters for each potential augmentation in the pool\n",
    "                 rand_aug_h_flip_enable=False,\n",
    "                 rand_aug_v_flip_enable=False,\n",
    "                 rand_aug_rotation_enable=False,\n",
    "                 rand_aug_rotation_degrees_options=None,\n",
    "                 rand_aug_brightness_enable=False,\n",
    "                 rand_aug_brightness_range=(1.0, 1.0),\n",
    "                 rand_aug_contrast_enable=False,\n",
    "                 rand_aug_contrast_range=(1.0, 1.0),\n",
    "                 rand_aug_gamma_enable=False,\n",
    "                 rand_aug_gamma_range=(1.0, 1.0),\n",
    "                 rand_aug_gaussian_noise_enable=False,\n",
    "                 rand_aug_gaussian_noise_std=0.0\n",
    "                ):\n",
    "\n",
    "        self.file_identifiers = file_identifiers; self.patches_dir = patches_dir; self.targets_dir = targets_dir\n",
    "        self.target_img_size = target_img_size; self.raw_band_to_idx_map = raw_band_to_idx_map\n",
    "        self.satlas_input_channel_names = satlas_input_channel_names\n",
    "        self.satlas_channel_to_source_raw_band_map = satlas_channel_to_source_raw_band_map\n",
    "        self.normalization_divisor = normalization_divisor\n",
    "\n",
    "        self.augmentations = augmentations\n",
    "        self.num_rand_augment_ops = num_rand_augment_ops\n",
    "\n",
    "        # Store all augmentation related parameters to be used in _init_augmentation_pool\n",
    "        self._h_flip_enable = rand_aug_h_flip_enable\n",
    "        self._v_flip_enable = rand_aug_v_flip_enable\n",
    "        self._rotation_enable = rand_aug_rotation_enable\n",
    "        self._rotation_degrees_options = rand_aug_rotation_degrees_options if rand_aug_rotation_degrees_options else [0]\n",
    "\n",
    "        self._brightness_enable = rand_aug_brightness_enable\n",
    "        self._brightness_range = rand_aug_brightness_range\n",
    "        self._contrast_enable = rand_aug_contrast_enable\n",
    "        self._contrast_range = rand_aug_contrast_range\n",
    "        self._gamma_enable = rand_aug_gamma_enable\n",
    "        self._gamma_range = rand_aug_gamma_range\n",
    "\n",
    "        self._noise_enable = rand_aug_gaussian_noise_enable\n",
    "        self._gaussian_noise_std = rand_aug_gaussian_noise_std\n",
    "\n",
    "        if self.augmentations and self.num_rand_augment_ops > 0:\n",
    "            self.augmentation_pool = self._init_augmentation_pool()\n",
    "            if not self.augmentation_pool:\n",
    "                print(\"WARNING: Augmentations enabled, N > 0, but augmentation pool is empty. Check enable flags in config.\")\n",
    "        else:\n",
    "            self.augmentation_pool = []\n",
    "\n",
    "    def _init_augmentation_pool(self):\n",
    "        pool = []\n",
    "\n",
    "        # Geometric Augmentations (affect image and mask)\n",
    "        if self._h_flip_enable:\n",
    "            def horizontal_flip(image, mask):\n",
    "                return TF.hflip(image), TF.hflip(mask)\n",
    "            pool.append(horizontal_flip)\n",
    "\n",
    "        if self._v_flip_enable:\n",
    "            def vertical_flip(image, mask):\n",
    "                return TF.vflip(image), TF.vflip(mask)\n",
    "            pool.append(vertical_flip)\n",
    "\n",
    "        if self._rotation_enable:\n",
    "            def rotation(image, mask):\n",
    "                angle = random.choice(self._rotation_degrees_options)\n",
    "                if angle != 0:\n",
    "                    image = TF.rotate(image, angle, interpolation=TF.InterpolationMode.BILINEAR)\n",
    "                    mask = TF.rotate(mask, angle, interpolation=TF.InterpolationMode.NEAREST)\n",
    "                return image, mask\n",
    "            pool.append(rotation)\n",
    "\n",
    "        # Radiometric Augmentations (affect image only)\n",
    "        # Corrected to handle multi-channel images by applying per-channel\n",
    "        if self._brightness_enable:\n",
    "            def adjust_brightness(image, mask):\n",
    "                factor = random.uniform(self._brightness_range[0], self._brightness_range[1])\n",
    "                if image.shape[0] not in [1, 3]: \n",
    "                    adjusted_channels = []\n",
    "                    for i in range(image.shape[0]):\n",
    "                        adjusted_channels.append(TF.adjust_brightness(image[i:i+1], factor))\n",
    "                    return torch.cat(adjusted_channels, dim=0), mask\n",
    "                else: # Standard 1 or 3 channel image\n",
    "                    return TF.adjust_brightness(image, factor), mask\n",
    "            pool.append(adjust_brightness)\n",
    "\n",
    "        if self._contrast_enable:\n",
    "            def adjust_contrast(image, mask):\n",
    "                factor = random.uniform(self._contrast_range[0], self._contrast_range[1])\n",
    "                if image.shape[0] not in [1, 3]: \n",
    "                    adjusted_channels = []\n",
    "                    for i in range(image.shape[0]):\n",
    "                        adjusted_channels.append(TF.adjust_contrast(image[i:i+1], factor))\n",
    "                    return torch.cat(adjusted_channels, dim=0), mask\n",
    "                else: # Standard 1 or 3 channel image\n",
    "                    return TF.adjust_contrast(image, factor), mask\n",
    "            pool.append(adjust_contrast)\n",
    "\n",
    "        if self._gamma_enable:\n",
    "            def adjust_gamma(image, mask):\n",
    "                gamma_val = max(0.1, random.uniform(self._gamma_range[0], self._gamma_range[1]))\n",
    "                if image.shape[0] not in [1, 3]: # If not grayscale or RGB, apply per channel\n",
    "                    adjusted_channels = []\n",
    "                    for i in range(image.shape[0]):\n",
    "                        # Apply to each channel (shape [1, H, W])\n",
    "                        adjusted_channels.append(TF.adjust_gamma(image[i:i+1], gamma_val, gain=1))\n",
    "                    return torch.cat(adjusted_channels, dim=0), mask\n",
    "                else: # Standard 1 or 3 channel image\n",
    "                     return TF.adjust_gamma(image, gamma_val, gain=1), mask\n",
    "            pool.append(adjust_gamma)\n",
    "\n",
    "        # Noise Augmentation (affect image only)\n",
    "        if self._noise_enable and self._gaussian_noise_std > 0:\n",
    "            def add_gaussian_noise(image, mask):\n",
    "                noise = torch.randn_like(image) * self._gaussian_noise_std # randn_like works for any shape\n",
    "                return torch.clamp(image + noise, 0.0, 1.0), mask\n",
    "            pool.append(add_gaussian_noise)\n",
    "\n",
    "        return pool\n",
    "\n",
    "    def __len__(self): return len(self.file_identifiers)\n",
    "\n",
    "    def _load_process_and_normalize_image(self, image_identifier):\n",
    "        # (This method remains unchanged)\n",
    "        image_filename = f\"{image_identifier}_S2.tif\"\n",
    "        image_path = os.path.join(self.patches_dir, image_filename)\n",
    "        with rasterio.open(image_path) as src: raw_image_data_from_file = src.read()\n",
    "        processed_bands_for_satlas = []\n",
    "        for target_satlas_channel_name in self.satlas_input_channel_names:\n",
    "            source_raw_band_name = self.satlas_channel_to_source_raw_band_map[target_satlas_channel_name]\n",
    "            raw_band_idx_in_file = self.raw_band_to_idx_map[source_raw_band_name]\n",
    "            processed_bands_for_satlas.append(raw_image_data_from_file[raw_band_idx_in_file])\n",
    "        satlas_stacked_image_np = np.stack(processed_bands_for_satlas, axis=0).astype(np.float32)\n",
    "        image_tensor = torch.from_numpy(satlas_stacked_image_np)\n",
    "        if image_tensor.shape[1:] != (self.target_img_size, self.target_img_size):\n",
    "            image_tensor = F.interpolate(image_tensor.unsqueeze(0),\n",
    "                                         size=(self.target_img_size, self.target_img_size),\n",
    "                                         mode='bilinear', align_corners=False).squeeze(0)\n",
    "        image_tensor = image_tensor / self.normalization_divisor\n",
    "        image_tensor = torch.clip(image_tensor, 0.0, 1.0)\n",
    "        return image_tensor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        identifier = self.file_identifiers[idx]\n",
    "        try:\n",
    "            image_tensor = self._load_process_and_normalize_image(identifier) # Shape: [C, H, W]\n",
    "            mask_filename = f\"{identifier}_Mask.tif\"; label_path = os.path.join(self.targets_dir, mask_filename)\n",
    "            with rasterio.open(label_path) as src: label = src.read(1)\n",
    "            label_tensor = F.interpolate(torch.tensor(label, dtype=torch.float32).unsqueeze(0).unsqueeze(0),\n",
    "                                         size=(self.target_img_size, self.target_img_size), mode='nearest').squeeze(0).squeeze(0).long() # Shape: [H, W]\n",
    "\n",
    "            if self.augmentations and self.augmentation_pool and self.num_rand_augment_ops > 0:\n",
    "                label_tensor_aug = label_tensor.unsqueeze(0)\n",
    "                num_ops_to_apply = min(self.num_rand_augment_ops, len(self.augmentation_pool))\n",
    "                chosen_ops = random.sample(self.augmentation_pool, num_ops_to_apply)\n",
    "\n",
    "                for op_func in chosen_ops:\n",
    "                    image_tensor, label_tensor_aug = op_func(image_tensor, label_tensor_aug)\n",
    "\n",
    "                label_tensor = label_tensor_aug.squeeze(0)\n",
    "\n",
    "            if image_tensor.shape!=(NUM_SATLAS_INPUT_BANDS,self.target_img_size,self.target_img_size) or \\\n",
    "               label_tensor.shape!=(self.target_img_size,self.target_img_size):\n",
    "                raise ValueError(f\"Shape mismatch for {identifier}. Img:{image_tensor.shape}, Lbl:{label_tensor.shape}\")\n",
    "\n",
    "            return image_tensor, label_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in __getitem__ for {identifier}: {e}\"); traceback.print_exc(); raise e\n",
    "# ============ DATA DISCOVERY ============ #\n",
    "print(\"\\n=========== Data Loading & Prep (allenai/satlaspretrain_models - Single GPU V16 - RandAugment) ============\") # Updated print\n",
    "image_files_pattern = os.path.join(PATCHES_DIR, \"Patch*_S2.tif\")\n",
    "all_image_filepaths = sorted(glob.glob(image_files_pattern))\n",
    "initial_file_identifiers = []\n",
    "if not all_image_filepaths: print(f\"ERROR: No image files found in {PATCHES_DIR}\")\n",
    "else: print(f\"Found {len(all_image_filepaths)} potential image files. Checking masks...\")\n",
    "for img_path in all_image_filepaths:\n",
    "    base_name = os.path.basename(img_path); identifier_match = re.match(r\"(Patch\\d+_W\\d+_\\d{8})_S2\\.tif\", base_name)\n",
    "    if identifier_match:\n",
    "        identifier = identifier_match.group(1); mask_path = os.path.join(TARGETS_DIR, f\"{identifier}_Mask.tif\")\n",
    "        if os.path.exists(mask_path): initial_file_identifiers.append(identifier)\n",
    "        else: print(f\"WARNING: Mask for {identifier} not found. Skipping.\")\n",
    "    else: print(f\"WARNING: Could not parse {base_name}. Skipping.\")\n",
    "print(f\"Found {len(initial_file_identifiers)} initial image-mask pairs.\")\n",
    "\n",
    "# ============ DATA INTEGRITY CHECK ============ #\n",
    "print(f\"\\nPerforming data integrity check on {len(initial_file_identifiers)} pairs...\")\n",
    "corrupted_identifiers, valid_identifiers = [], []\n",
    "if not initial_file_identifiers: print(\"No identifiers to check.\")\n",
    "else:\n",
    "    for identifier in initial_file_identifiers:\n",
    "        image_path = os.path.join(PATCHES_DIR, f\"{identifier}_S2.tif\"); problem, msgs = False, []\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src: image_data_raw_check = src.read()\n",
    "            if image_data_raw_check.shape[0] < NUM_RAW_BANDS_AVAILABLE:\n",
    "                msgs.append(f\"File has {image_data_raw_check.shape[0]} bands, expected {NUM_RAW_BANDS_AVAILABLE}.\"); problem = True\n",
    "            else:\n",
    "                data_to_check_integrity = image_data_raw_check[:NUM_RAW_BANDS_AVAILABLE, :, :].astype(np.float32)\n",
    "                if np.isnan(data_to_check_integrity).any(): msgs.append(\"NaNs\"); problem = True\n",
    "                if data_to_check_integrity.min() < -1000: msgs.append(f\"Low raw values: {data_to_check_integrity.min()}\"); problem = True\n",
    "                if data_to_check_integrity.max() > 20000: msgs.append(f\"High raw values: {data_to_check_integrity.max()}\"); problem = True\n",
    "                if data_to_check_integrity.size > 0 and not problem:\n",
    "                    is_uniform = True\n",
    "                    for i in range(data_to_check_integrity.shape[0]):\n",
    "                        if data_to_check_integrity.shape[1]>0 and data_to_check_integrity.shape[2]>0:\n",
    "                            if not np.allclose(data_to_check_integrity[i], data_to_check_integrity[i,0,0], atol=1e-1): is_uniform = False; break\n",
    "                        elif data_to_check_integrity.shape[1] == 0 or data_to_check_integrity.shape[2] == 0: is_uniform = False; break\n",
    "                    if is_uniform and data_to_check_integrity.shape[1]>0 : msgs.append(\"All raw bands appear uniform\"); problem = True\n",
    "                elif data_to_check_integrity.size == 0: msgs.append(\"Empty raw data\"); problem = True\n",
    "            if problem: print(f\"WARNING: {identifier} issues: {'; '.join(msgs)}. Skipping.\"); corrupted_identifiers.append(identifier)\n",
    "            else: valid_identifiers.append(identifier)\n",
    "        except Exception as e: print(f\"ERROR checking {identifier}: {e}. Skipping.\"); corrupted_identifiers.append(identifier)\n",
    "print(f\"Integrity check complete. Corrupted: {len(corrupted_identifiers)}.\")\n",
    "clean_identifiers = valid_identifiers; num_clean_patches = len(clean_identifiers)\n",
    "print(f\"Clean patches: {num_clean_patches}\")\n",
    "\n",
    "\n",
    "# ============ DATA SPLIT AND LOADERS (pin_memory=False, num_workers=0) ============ #\n",
    "train_ds, val_ds, train_loader, val_loader = None, None, None, None\n",
    "if num_clean_patches > 0:\n",
    "    random.shuffle(clean_identifiers)\n",
    "    split_idx = int(num_clean_patches * 0.8)\n",
    "    train_ids, val_ids = (clean_identifiers[:split_idx], clean_identifiers[split_idx:]) if num_clean_patches >=2 else (clean_identifiers, [])\n",
    "    if not val_ids and len(train_ids) > 1 : val_ids = [train_ids.pop()]\n",
    "    print(f\"Training IDs: {len(train_ids)}, Validation IDs: {len(val_ids)}\")\n",
    "\n",
    "    if train_ids:\n",
    "        train_ds = CerealSensingDataset(\n",
    "            file_identifiers=train_ids,\n",
    "            patches_dir=PATCHES_DIR,\n",
    "            targets_dir=TARGETS_DIR,\n",
    "            target_img_size=IMG_SIZE,\n",
    "            raw_band_to_idx_map=RAW_BAND_TO_IDX_MAP,\n",
    "            satlas_input_channel_names=SATLAS_INPUT_CHANNEL_NAMES,\n",
    "            satlas_channel_to_source_raw_band_map=SATLAS_CHANNEL_TO_SOURCE_RAW_BAND_MAP,\n",
    "            normalization_divisor=NORMALIZATION_DIVISOR,\n",
    "            augmentations=APPLY_AUGMENTATIONS_TRAIN_SET, # Master switch\n",
    "            num_rand_augment_ops=NUM_RAND_AUGMENT_OPS,   # N for RandAugment\n",
    "            # Pass all RandAugment config parameters\n",
    "            rand_aug_h_flip_enable=RAND_AUG_H_FLIP_ENABLE,\n",
    "            rand_aug_v_flip_enable=RAND_AUG_V_FLIP_ENABLE,\n",
    "            rand_aug_rotation_enable=RAND_AUG_ROTATION_ENABLE,\n",
    "            rand_aug_rotation_degrees_options=RAND_AUG_ROTATION_DEGREES_OPTIONS,\n",
    "            rand_aug_brightness_enable=RAND_AUG_BRIGHTNESS_ENABLE,\n",
    "            rand_aug_brightness_range=RAND_AUG_BRIGHTNESS_RANGE,\n",
    "            rand_aug_contrast_enable=RAND_AUG_CONTRAST_ENABLE,\n",
    "            rand_aug_contrast_range=RAND_AUG_CONTRAST_RANGE,\n",
    "            rand_aug_gamma_enable=RAND_AUG_GAMMA_ENABLE,\n",
    "            rand_aug_gamma_range=RAND_AUG_GAMMA_RANGE,\n",
    "            rand_aug_gaussian_noise_enable=RAND_AUG_GAUSSIAN_NOISE_ENABLE,\n",
    "            rand_aug_gaussian_noise_std=RAND_AUG_GAUSSIAN_NOISE_STD\n",
    "        )\n",
    "        train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=False)\n",
    "        print(f\"Train DataLoader: {len(train_loader.dataset)} samples. Augmentations: {APPLY_AUGMENTATIONS_TRAIN_SET}, N_ops={NUM_RAND_AUGMENT_OPS if APPLY_AUGMENTATIONS_TRAIN_SET else 0}\")\n",
    "\n",
    "    if val_ids:\n",
    "        val_ds = CerealSensingDataset(\n",
    "            file_identifiers=val_ids,\n",
    "            patches_dir=PATCHES_DIR,\n",
    "            targets_dir=TARGETS_DIR,\n",
    "            target_img_size=IMG_SIZE,\n",
    "            raw_band_to_idx_map=RAW_BAND_TO_IDX_MAP,\n",
    "            satlas_input_channel_names=SATLAS_INPUT_CHANNEL_NAMES,\n",
    "            satlas_channel_to_source_raw_band_map=SATLAS_CHANNEL_TO_SOURCE_RAW_BAND_MAP,\n",
    "            normalization_divisor=NORMALIZATION_DIVISOR,\n",
    "            augmentations=False # IMPORTANT: No augmentations for validation set\n",
    "        )\n",
    "        val_loader = DataLoader(val_ds, BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "        print(f\"Val DataLoader: {len(val_loader.dataset)} samples. Augmentations: False\")\n",
    "    elif not val_ids and train_ids:\n",
    "        print(\"WARNING: Validation dataset is empty (but training data exists).\")\n",
    "    elif not train_ids :\n",
    "        print(\"WARNING: Training dataset is empty, so validation dataset is also empty.\")\n",
    "else:\n",
    "    print(\"ERROR: No clean patches to create datasets.\")\n",
    "# Quick Visualisation (Sanity Check - allenai/satlaspretrain_models V16)\n",
    "if train_ds and len(train_ds) > 0:\n",
    "    try:\n",
    "        print(\"\\n--- Visualizing a sample from TRAIN_DS (allenai/satlaspretrain_models V16, TCI view, Geometric Aug) ---\") # Updated print\n",
    "        sample_idx = 0 ; sample_img_tensor, sample_mask_tensor = train_ds[sample_idx] # This will apply augmentations if enabled\n",
    "        print(f\"Sample Img Shape: {sample_img_tensor.shape}, Mask Shape: {sample_mask_tensor.shape}, Unique Mask: {torch.unique(sample_mask_tensor)}\")\n",
    "\n",
    "        tci_view_tensor = sample_img_tensor[:3, :, :].cpu() # Assuming first 3 channels are R,G,B for TCI\n",
    "        print(f\"TCI View (Ch 0,1,2 - SR data / {NORMALIZATION_DIVISOR}) - Min: {tci_view_tensor.min():.4f}, Max: {tci_view_tensor.max():.4f}, Mean: {tci_view_tensor.mean():.4f}\")\n",
    "\n",
    "        GAIN_FOR_VISUALIZATION = 3.5\n",
    "        img_for_vis_gained = tci_view_tensor.numpy().transpose(1, 2, 0) * GAIN_FOR_VISUALIZATION\n",
    "        img_display_np = np.clip(img_for_vis_gained, 0, 1)\n",
    "\n",
    "        fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "        axs[0].imshow(img_display_np); axs[0].set_title(f'Input ID: {train_ds.file_identifiers[sample_idx]} (TCI, Vis Gain x{GAIN_FOR_VISUALIZATION})\\nAugmented Sample'); axs[0].axis('off')\n",
    "        axs[1].imshow(sample_mask_tensor.cpu().numpy(), cmap='gray'); axs[1].set_title('Mask (Augmented)'); axs[1].axis('off')\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "        print(\"\\n--- Ranges for ALL 9 Normalized Channels in Sample (all divided by 8160): ---\")\n",
    "        for i, ch_name_vis in enumerate(SATLAS_INPUT_CHANNEL_NAMES):\n",
    "            ch_data = sample_img_tensor[i, :, :].cpu()\n",
    "            source_raw_band = SATLAS_CHANNEL_TO_SOURCE_RAW_BAND_MAP[ch_name_vis]\n",
    "            print(f\"  Channel {i} ('{ch_name_vis}' from '{source_raw_band}'): Min={ch_data.min():.6f}, Max={ch_data.max():.6f}, Mean={ch_data.mean():.6f}\")\n",
    "\n",
    "    except Exception as e: print(f\"Visualization error: {e}\"); traceback.print_exc()\n",
    "else: print(\"Training dataset empty. Skipping visualization.\")\n",
    "\n",
    "# Load Satlas Model using Official `weights_manager` (allenai/satlaspretrain_models - V16)\n",
    "print(f\"\\n--- Loading Satlas Model via weights_manager: {SATLAS_MODEL_IDENTIFIER} ---\")\n",
    "satlas_full_segmentation_model = None\n",
    "try:\n",
    "    weights_manager = satlaspretrain_models.Weights()\n",
    "\n",
    "    satlas_full_segmentation_model = weights_manager.get_pretrained_model(\n",
    "        model_identifier=SATLAS_MODEL_IDENTIFIER,\n",
    "        fpn=True,\n",
    "        head=satlaspretrain_models.Head.SEGMENT,\n",
    "        num_categories=NUM_CLASSES\n",
    "    )\n",
    "    print(f\"Successfully loaded Satlas model with segmentation head: {SATLAS_MODEL_IDENTIFIER}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Satlas model via weights_manager: {e}\")\n",
    "    traceback.print_exc()\n",
    "    satlas_full_segmentation_model = None\n",
    "\n",
    "# --- Horizontal Line ---\n",
    "class LitSegmentationModel(LightningModule):\n",
    "    def __init__(self, full_satlas_model, learning_rate, weight_decay, num_classes, class_names=None, freeze_backbone_fpn=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['full_satlas_model'])\n",
    "        self.model = full_satlas_model\n",
    "\n",
    "        if freeze_backbone_fpn:\n",
    "            frozen_count = 0\n",
    "            if hasattr(self.model, 'backbone'):\n",
    "                for param in self.model.backbone.parameters(): param.requires_grad = False\n",
    "                print(\"Satlas backbone parameters frozen.\")\n",
    "                frozen_count +=1\n",
    "            if hasattr(self.model, 'fpn'):\n",
    "                 for param in self.model.fpn.parameters(): param.requires_grad = False\n",
    "                 print(\"Satlas FPN parameters frozen.\")\n",
    "                 frozen_count +=1\n",
    "            if frozen_count == 0: print(\"WARNING: Could not find 'backbone' or 'fpn' attributes directly on self.model to freeze.\")\n",
    "            if hasattr(self.model, 'head'): print(\"Segmentation head (self.model.head) parameters are expected to be trainable.\")\n",
    "\n",
    "        self.class_weights_tensor = None # You might want to compute and set this\n",
    "        self.class_names = class_names if class_names else [f\"class_{i}\" for i in range(num_classes)]\n",
    "\n",
    "        # Updated MetricCollection to include per-class accuracy\n",
    "        metrics = MetricCollection({\n",
    "            'accuracy_overall': Accuracy(task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "            'f1_score_macro': F1Score(task=\"multiclass\", num_classes=num_classes, average='macro'),\n",
    "            'jaccard_index_macro': JaccardIndex(task=\"multiclass\", num_classes=num_classes, average='macro'),\n",
    "            'accuracy_per_class': Accuracy(task=\"multiclass\", num_classes=num_classes, average='none'), # <-- ADDED\n",
    "            'jaccard_index_per_class': JaccardIndex(task=\"multiclass\", num_classes=num_classes, average='none'),\n",
    "            'f1_score_per_class': F1Score(task=\"multiclass\", num_classes=num_classes, average='none')\n",
    "        })\n",
    "        self.val_metrics = metrics.clone(prefix='val_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_output = self.model(x)\n",
    "        # The UNetDecoder in satlaspretrain_models might return (logits, None)\n",
    "        if isinstance(model_output, tuple):\n",
    "            logits = model_output[0] # Take the first element, which should be the main logits\n",
    "        else:\n",
    "            logits = model_output \n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch; logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y, weight=(self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None))\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True); return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch; logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y, weight=(self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None))\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True, sync_dist=True); self.val_metrics.update(torch.argmax(logits, dim=1), y); return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics_output = self.val_metrics.compute()\n",
    "        for name, value in metrics_output.items():\n",
    "            is_prog_bar = name in [\"val_f1_score_macro\", \"val_jaccard_index_macro\"] # Overall metrics for progress bar\n",
    "\n",
    "            # Handles per-class metrics (like Jaccard, F1, and now Accuracy)\n",
    "            if isinstance(value, torch.Tensor) and value.numel() == self.hparams.num_classes:\n",
    "                for i in range(self.hparams.num_classes):\n",
    "                    class_metric_name = f\"{name}_{self.class_names[i]}\" # e.g., val_accuracy_per_class_cereal\n",
    "                    prog_bar_metric_name, log_to_prog_bar = None, False\n",
    "\n",
    "                    # Specific handling for \"cereal\" class IoU and F1 on progress bar\n",
    "                    if self.class_names[i] == \"cereal\":\n",
    "                        if name == \"val_jaccard_index_per_class\":\n",
    "                            prog_bar_metric_name, log_to_prog_bar = \"val_iou_cereal\", True\n",
    "                        elif name == \"val_f1_score_per_class\":\n",
    "                            prog_bar_metric_name, log_to_prog_bar = \"val_f1_cereal\", True\n",
    "\n",
    "\n",
    "                    if prog_bar_metric_name and log_to_prog_bar:\n",
    "                        # Log special prog_bar name (e.g. val_iou_cereal) and the full name to CSV logger\n",
    "                        self.log(prog_bar_metric_name, value[i], prog_bar=True, logger=False, sync_dist=True)\n",
    "                        self.log(class_metric_name, value[i], prog_bar=False, logger=True, sync_dist=True)\n",
    "                    else:\n",
    "                        # Log the full class metric name to CSV logger only (e.g., val_accuracy_per_class_non_cereal)\n",
    "                        self.log(class_metric_name, value[i], prog_bar=False, logger=True, sync_dist=True)\n",
    "            else:\n",
    "                # Handles overall metrics (e.g. val_loss, val_f1_score_macro)\n",
    "                self.log(name, value, prog_bar=is_prog_bar, logger=True, sync_dist=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "\n",
    "# Re-instantiate the LightningModule\n",
    "# This part should be run after Cell 6 successfully loads satlas_full_segmentation_model\n",
    "CLASS_NAMES_FOR_LOGGING = [\"non_cereal\", \"cereal\"] # Ensure this matches your classes\n",
    "lightning_model = None # Reset before re-instantiation\n",
    "\n",
    "if 'satlas_full_segmentation_model' in locals() and satlas_full_segmentation_model is not None:\n",
    "    lightning_model = LitSegmentationModel(\n",
    "        full_satlas_model=satlas_full_segmentation_model,\n",
    "        learning_rate=LR, # Assumes LR is defined in Cell 2\n",
    "        weight_decay=WEIGHT_DECAY, # Assumes WEIGHT_DECAY is defined in Cell 2\n",
    "        num_classes=NUM_CLASSES, # Assumes NUM_CLASSES is defined in Cell 2\n",
    "        class_names=CLASS_NAMES_FOR_LOGGING,\n",
    "        freeze_backbone_fpn=FREEZE_BACKBONE_FPN # Assumes FREEZE_BACKBONE_FPN is defined in Cell 2\n",
    "    )\n",
    "    print(\"LitSegmentationModel re-instantiated with per-class accuracy.\")\n",
    "else:\n",
    "    print(\"ERROR: satlas_full_segmentation_model not loaded (from Cell 6). Cannot instantiate LitSegmentationModel.\")\n",
    "# Training (Simplified for Single GPU - V16)\n",
    "# --- CUDA Initialization Check ---\n",
    "if DEVICE == \"cuda\" and torch.cuda.is_available():\n",
    "    if torch.cuda.is_initialized():\n",
    "        print(\"WARNING FROM DEBUG: CUDA IS ALREADY INITIALIZED before Trainer instantiation!\")\n",
    "    else:\n",
    "        print(\"INFO FROM DEBUG: CUDA is NOT yet initialized before Trainer instantiation. This is ideal.\")\n",
    "# --- End of debug check ---\n",
    "\n",
    "csv_logger = CSVLogger(LOGS_DIR_ACTUAL, name=\"cereal_seg_satlas_singleGPU_v16_geom_aug_run\") # Updated logger name\n",
    "print(f\"Logs: {csv_logger.log_dir}\")\n",
    "loss_cb = ModelCheckpoint(CHECKPOINT_SAVE_DIR_ACTUAL, 'model_singleGPU_geom_loss-{epoch:02d}-{val_loss:.3f}', monitor='val_loss', mode='min', save_top_k=1, verbose=True)\n",
    "iou_cb = ModelCheckpoint(CHECKPOINT_SAVE_DIR_ACTUAL, 'model_singleGPU_geom_iou_cereal-{epoch:02d}-{val_iou_cereal:.3f}', monitor='val_iou_cereal', mode='max', save_top_k=1, verbose=True)\n",
    "early_stop_cb = EarlyStopping(EARLY_STOPPING_MONITOR, patience=EARLY_STOPPING_PATIENCE, verbose=True, mode=(\"min\" if \"loss\" in EARLY_STOPPING_MONITOR else \"max\"))\n",
    "\n",
    "if lightning_model and train_loader:\n",
    "    trainer_accelerator = DEVICE\n",
    "    trainer_devices_setting = 1\n",
    "    trainer_strategy = \"auto\"\n",
    "\n",
    "    if DEVICE == \"cuda\" and torch.cuda.is_available():\n",
    "        print(f\"INFO: CUDA is available. Configuring for single GPU training on the first GPU.\")\n",
    "        trainer_devices_setting = [0] # Explicitly use the first GPU (index 0)\n",
    "    elif DEVICE == \"cpu\":\n",
    "        print(f\"INFO: Configuring for CPU training.\")\n",
    "        trainer_accelerator = \"cpu\"\n",
    "    else:\n",
    "        print(f\"WARNING: DEVICE='{DEVICE}' but CUDA not actually available. Forcing CPU training.\")\n",
    "        trainer_accelerator = \"cpu\"\n",
    "        trainer_devices_setting = 1\n",
    "\n",
    "    trainer = Trainer(accelerator=trainer_accelerator,\n",
    "                      devices=trainer_devices_setting,\n",
    "                      strategy=trainer_strategy,\n",
    "                      max_epochs=EPOCHS,\n",
    "                      logger=csv_logger,\n",
    "                      callbacks=[early_stop_cb, loss_cb, iou_cb],\n",
    "                      gradient_clip_val=0.5) \n",
    "\n",
    "    print(f\"Trainer initialized: accelerator='{trainer_accelerator}', devices={trainer_devices_setting}, strategy='{trainer_strategy}'\")\n",
    "    print(f\"Starting training: {SATLAS_MODEL_IDENTIFIER} (all bands / {NORMALIZATION_DIVISOR}, Geometric Aug)...\") \n",
    "    try:\n",
    "        val_dl_arg = val_loader if val_loader and hasattr(val_loader, 'dataset') and len(val_loader.dataset)>0 else None\n",
    "        cbs_to_use = trainer.callbacks\n",
    "        if not val_dl_arg and cbs_to_use:\n",
    "            print(\"No val_loader, adjusting callbacks that monitor validation metrics.\")\n",
    "            original_callbacks = list(cbs_to_use); cbs_to_use = []\n",
    "            for cb_instance in original_callbacks:\n",
    "                monitor_attr = getattr(cb_instance, 'monitor', None)\n",
    "                if monitor_attr and monitor_attr.startswith(\"val_\"): print(f\"Removing callback: {cb_instance.__class__.__name__} on {monitor_attr}\")\n",
    "                else: cbs_to_use.append(cb_instance)\n",
    "            trainer.callbacks = cbs_to_use if cbs_to_use else None\n",
    "\n",
    "        trainer.fit(lightning_model, train_dataloaders=train_loader, val_dataloaders=val_dl_arg)\n",
    "        print(\"Training finished.\")\n",
    "        if loss_cb and hasattr(loss_cb, 'best_model_path') and loss_cb.best_model_path: print(f\"Best loss model: {loss_cb.best_model_path}\")\n",
    "        if iou_cb and hasattr(iou_cb, 'best_model_path') and iou_cb.best_model_path: print(f\"Best IoU Cereal model: {iou_cb.best_model_path}\")\n",
    "    except Exception as e: print(f\"Training error: {e}\"); traceback.print_exc()\n",
    "else: print(\"ERROR: Training prerequisites not met (lightning_model or train_loader is None).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
