{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809237d1-05f6-4c8e-8951-4301d1354678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, JaccardIndex\n",
    "from torchmetrics.collections import MetricCollection\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "from terratorch.tasks import SemanticSegmentationTask\n",
    "import rasterio\n",
    "import glob\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "BASE_DATA_DIR_ACTUAL = \"CerealDataBetter\"\n",
    "CHECKPOINT_SAVE_DIR_ACTUAL = os.path.join(os.getcwd(), \"checkpoints_auto_augment\")\n",
    "LOGS_DIR_ACTUAL = os.path.join(os.getcwd(), \"metrics_auto_augment\")\n",
    "PATCHES_DIR = os.path.join(BASE_DATA_DIR_ACTUAL, \"GEE_WeeklyPatches\")\n",
    "TARGETS_DIR = os.path.join(BASE_DATA_DIR_ACTUAL, \"GEE_WeeklyMasks\")\n",
    "\n",
    "os.makedirs(CHECKPOINT_SAVE_DIR_ACTUAL, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR_ACTUAL, exist_ok=True)\n",
    "\n",
    "EXPECTED_BANDS_ORDER = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\"]\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "LR = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "HEAD_DROPOUT = 0.2\n",
    "FREEZE_BACKBONE = False\n",
    "RAND_AUGMENT_N = 2\n",
    "ROTATION_DEGREES = 180\n",
    "BRIGHTNESS_RANGE = (0.9, 1.1)\n",
    "CONTRAST_RANGE = (0.9, 1.1)\n",
    "GAMMA_RANGE = (0.9, 1.1)\n",
    "GAUSSIAN_NOISE_STD = 0.01\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "EARLY_STOPPING_MONITOR = \"val_loss\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class CerealSensingDataset(Dataset):\n",
    "    def __init__(self, file_identifiers, patches_dir, targets_dir, target_img_size,\n",
    "                 augmentations=False,\n",
    "                 rand_augment_n=0,\n",
    "                 rotation_degrees=0,\n",
    "                 brightness_range=(1.0, 1.0),\n",
    "                 contrast_range=(1.0, 1.0),\n",
    "                 gamma_range=(1.0, 1.0),\n",
    "                 gaussian_noise_std=0.0):\n",
    "        self.file_identifiers = file_identifiers\n",
    "        self.patches_dir = patches_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.target_img_size = target_img_size\n",
    "        self.augmentations = augmentations\n",
    "        self.rand_augment_n = rand_augment_n\n",
    "        self.rotation_degrees = rotation_degrees\n",
    "        self.brightness_range = brightness_range\n",
    "        self.contrast_range = contrast_range\n",
    "        self.gamma_range = gamma_range\n",
    "        self.gaussian_noise_std = gaussian_noise_std\n",
    "        self.augmentation_pool = [\n",
    "            self._aug_hflip,\n",
    "            self._aug_vflip,\n",
    "            self._aug_rotate,\n",
    "            self._aug_brightness_single_channel,\n",
    "            self._aug_contrast_single_channel,\n",
    "            self._aug_gamma_single_channel\n",
    "        ]\n",
    "        if self.gaussian_noise_std > 0:\n",
    "            self.augmentation_pool.append(self._aug_gaussian_noise_all_channels)\n",
    "\n",
    "    def _aug_hflip(self, image_tensor, mask_tensor_float):\n",
    "        return TF.hflip(image_tensor), TF.hflip(mask_tensor_float)\n",
    "\n",
    "    def _aug_vflip(self, image_tensor, mask_tensor_float):\n",
    "        return TF.vflip(image_tensor), TF.vflip(mask_tensor_float)\n",
    "\n",
    "    def _aug_rotate(self, image_tensor, mask_tensor_float):\n",
    "        if self.rotation_degrees > 0:\n",
    "            angle = random.uniform(-self.rotation_degrees, self.rotation_degrees)\n",
    "            image_tensor = TF.rotate(image_tensor, angle, interpolation=TF.InterpolationMode.BILINEAR)\n",
    "            mask_tensor_float = TF.rotate(mask_tensor_float.unsqueeze(0), angle, interpolation=TF.InterpolationMode.NEAREST).squeeze(0)\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_brightness_single_channel(self, image_tensor, mask_tensor_float):\n",
    "        num_channels = image_tensor.shape[0]\n",
    "        channel_to_aug = random.randint(0, num_channels - 1)\n",
    "        factor = random.uniform(self.brightness_range[0], self.brightness_range[1])\n",
    "        image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_brightness(\n",
    "            image_tensor[channel_to_aug:channel_to_aug+1], factor\n",
    "        )\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_contrast_single_channel(self, image_tensor, mask_tensor_float):\n",
    "        num_channels = image_tensor.shape[0]\n",
    "        channel_to_aug = random.randint(0, num_channels - 1)\n",
    "        factor = random.uniform(self.contrast_range[0], self.contrast_range[1])\n",
    "        image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_contrast(\n",
    "            image_tensor[channel_to_aug:channel_to_aug+1], factor\n",
    "        )\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_gamma_single_channel(self, image_tensor, mask_tensor_float):\n",
    "        num_channels = image_tensor.shape[0]\n",
    "        channel_to_aug = random.randint(0, num_channels - 1)\n",
    "        gamma = random.uniform(self.gamma_range[0], self.gamma_range[1])\n",
    "        gamma = max(0.1, gamma)\n",
    "        channel_non_neg = torch.clamp(image_tensor[channel_to_aug:channel_to_aug+1], min=0)\n",
    "        image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_gamma(channel_non_neg, gamma)\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_gaussian_noise_all_channels(self, image_tensor, mask_tensor_float):\n",
    "        if self.gaussian_noise_std > 0:\n",
    "            noise = torch.randn_like(image_tensor) * self.gaussian_noise_std\n",
    "            image_tensor = image_tensor + noise\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_identifiers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        identifier = self.file_identifiers[idx]\n",
    "        image_filename = f\"{identifier}_S2.tif\"\n",
    "        mask_filename = f\"{identifier}_Mask.tif\"\n",
    "        image_path = os.path.join(self.patches_dir, image_filename)\n",
    "        label_path = os.path.join(self.targets_dir, mask_filename)\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                image = src.read()\n",
    "                if image.shape[0] != 6:\n",
    "                    raise ValueError(f\"Image {identifier} has {image.shape[0]} bands, expected 6.\")\n",
    "            with rasterio.open(label_path) as src:\n",
    "                label = src.read(1)\n",
    "\n",
    "            image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "            label_tensor_float = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "            image_tensor = F.interpolate(image_tensor.unsqueeze(0),\n",
    "                                         size=(self.target_img_size, self.target_img_size),\n",
    "                                         mode='bilinear', align_corners=False).squeeze(0)\n",
    "            label_tensor_float = F.interpolate(label_tensor_float.unsqueeze(0).unsqueeze(0),\n",
    "                                         size=(self.target_img_size, self.target_img_size),\n",
    "                                         mode='nearest').squeeze(0).squeeze(0)\n",
    "\n",
    "            if self.augmentations and self.rand_augment_n > 0 and self.augmentation_pool:\n",
    "                num_ops_to_apply = min(self.rand_augment_n, len(self.augmentation_pool))\n",
    "                ops_to_apply = random.sample(self.augmentation_pool, num_ops_to_apply)\n",
    "                for op_func in ops_to_apply:\n",
    "                    image_tensor, label_tensor_float = op_func(image_tensor, label_tensor_float)\n",
    "\n",
    "            label_tensor = label_tensor_float.long()\n",
    "            image_tensor = image_tensor.float()\n",
    "\n",
    "            if image_tensor.shape != (6, self.target_img_size, self.target_img_size) or \\\n",
    "               label_tensor.shape != (self.target_img_size, self.target_img_size):\n",
    "                raise ValueError(f\"Shape mismatch for {identifier} post-processing. Img: {image_tensor.shape}, Lbl: {label_tensor.shape}\")\n",
    "            return image_tensor, label_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading/processing {identifier}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise e\n",
    "\n",
    "image_files_pattern = os.path.join(PATCHES_DIR, \"Patch*_S2.tif\")\n",
    "all_image_filepaths = sorted(glob.glob(image_files_pattern))\n",
    "initial_file_identifiers = []\n",
    "for img_path in all_image_filepaths:\n",
    "    base_name = os.path.basename(img_path)\n",
    "    identifier_match = re.match(r\"(Patch\\d+_W\\d+_\\d{8})_S2\\.tif\", base_name)\n",
    "    if identifier_match:\n",
    "        identifier = identifier_match.group(1)\n",
    "        mask_path = os.path.join(TARGETS_DIR, f\"{identifier}_Mask.tif\")\n",
    "        if os.path.exists(mask_path):\n",
    "            initial_file_identifiers.append(identifier)\n",
    "\n",
    "corrupted_identifiers, valid_identifiers = [], []\n",
    "for identifier in initial_file_identifiers:\n",
    "    image_path = os.path.join(PATCHES_DIR, f\"{identifier}_S2.tif\")\n",
    "    try:\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image_data = src.read()\n",
    "        problem = False\n",
    "        if np.isnan(image_data).any():\n",
    "            problem = True\n",
    "        if image_data.max() > 65535 or image_data.min() < -32768:\n",
    "            problem = True\n",
    "        if image_data.size > 0:\n",
    "            is_uniform_check = True\n",
    "            for band_idx_check in range(image_data.shape[0]):\n",
    "                first_val_band_check = image_data[band_idx_check,0,0] if image_data.shape[1] > 0 and image_data.shape[2] > 0 else None\n",
    "                if first_val_band_check is not None:\n",
    "                    if np.issubdtype(image_data[band_idx_check].dtype, np.floating):\n",
    "                        if not np.allclose(image_data[band_idx_check], first_val_band_check, atol=1e-5):\n",
    "                            is_uniform_check = False\n",
    "                            break\n",
    "                    else:\n",
    "                        if not np.all(image_data[band_idx_check] == first_val_band_check):\n",
    "                            is_uniform_check = False\n",
    "                            break\n",
    "            if is_uniform_check and image_data.shape[1] > 0 and image_data.shape[2] > 0:\n",
    "                problem = True\n",
    "        else:\n",
    "            problem = True\n",
    "        if problem:\n",
    "            corrupted_identifiers.append(identifier)\n",
    "        else:\n",
    "            valid_identifiers.append(identifier)\n",
    "    except Exception as e:\n",
    "        corrupted_identifiers.append(identifier)\n",
    "\n",
    "clean_identifiers = valid_identifiers\n",
    "num_clean_patches = len(clean_identifiers)\n",
    "\n",
    "train_ds, val_ds, train_loader, val_loader = None, None, None, None\n",
    "if num_clean_patches > 0:\n",
    "    random.shuffle(clean_identifiers)\n",
    "    if num_clean_patches >= 2:\n",
    "        num_train = max(1, int(num_clean_patches * 0.8))\n",
    "        train_ids, val_ids = clean_identifiers[:num_train], clean_identifiers[num_train:]\n",
    "        if not val_ids and len(train_ids) > 1:\n",
    "            val_ids = [train_ids.pop()]\n",
    "    elif num_clean_patches == 1:\n",
    "        train_ids, val_ids = clean_identifiers, []\n",
    "    else:\n",
    "        train_ids, val_ids = [], []\n",
    "\n",
    "    if train_ids:\n",
    "        train_ds = CerealSensingDataset(\n",
    "            train_ids, PATCHES_DIR, TARGETS_DIR, IMG_SIZE,\n",
    "            augmentations=True,\n",
    "            rand_augment_n=RAND_AUGMENT_N,\n",
    "            rotation_degrees=ROTATION_DEGREES,\n",
    "            brightness_range=BRIGHTNESS_RANGE,\n",
    "            contrast_range=CONTRAST_RANGE,\n",
    "            gamma_range=GAMMA_RANGE,\n",
    "            gaussian_noise_std=GAUSSIAN_NOISE_STD\n",
    "        )\n",
    "        num_data_workers = 4\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_data_workers, pin_memory=True if DEVICE==\"cuda\" else False, persistent_workers=True if num_data_workers > 0 else False)\n",
    "    if val_ids:\n",
    "        val_ds = CerealSensingDataset(val_ids, PATCHES_DIR, TARGETS_DIR, IMG_SIZE, augmentations=False)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_data_workers, pin_memory=True if DEVICE==\"cuda\" else False, persistent_workers=True if num_data_workers > 0 else False)\n",
    "\n",
    "model_args = {\n",
    "    \"backbone\": \"prithvi_eo_v2_300\", \"backbone_pretrained\": True,\n",
    "    \"backbone_bands\": EXPECTED_BANDS_ORDER, \"decoder\": \"FCNDecoder\",\n",
    "    \"decoder_channels\": 256, \"head_dropout\": HEAD_DROPOUT,\n",
    "    \"num_classes\": NUM_CLASSES, \"rescale\": True\n",
    "}\n",
    "task_config_obj = SemanticSegmentationTask(\n",
    "    model_args=model_args, model_factory=\"EncoderDecoderFactory\", loss=\"ce\",\n",
    "    freeze_backbone=FREEZE_BACKBONE, lr=LR, optimizer=\"adamw\",\n",
    "    optimizer_hparams={\"weight_decay\": WEIGHT_DECAY}\n",
    ")\n",
    "\n",
    "class LitSegmentationModel(LightningModule):\n",
    "    def __init__(self, model_arch, learning_rate, weight_decay, num_classes, class_names=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model_arch'])\n",
    "        self.model = model_arch\n",
    "        self.class_weights_tensor = None\n",
    "        self.class_names = class_names if class_names else [f\"class{i}\" for i in range(num_classes)]\n",
    "        metrics = MetricCollection({\n",
    "            'accuracy_overall': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='micro'),\n",
    "            'precision_macro': Precision(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'recall_macro': Recall(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'f1_score_macro': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'jaccard_index_per_class': JaccardIndex(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'accuracy_per_class': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'precision_per_class': Precision(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'recall_per_class': Recall(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'f1_score_per_class': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "        })\n",
    "        self.val_metrics = metrics.clone(prefix='val_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out_struct = self.model(x)\n",
    "        logits = out_struct.output\n",
    "        weights = self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(logits, y, weight=weights)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out_struct = self.model(x)\n",
    "        logits = out_struct.output\n",
    "        weights = self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(logits, y, weight=weights)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        preds_classes = torch.argmax(logits, dim=1)\n",
    "        self.val_metrics.update(preds_classes, y)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics_output = self.val_metrics.compute()\n",
    "        for name, value in metrics_output.items():\n",
    "            log_to_prog_bar = False\n",
    "            prog_bar_name_override = None\n",
    "            if name in [\"val_accuracy_overall\", \"val_f1_score_macro\"]:\n",
    "                log_to_prog_bar = True\n",
    "            if isinstance(value, torch.Tensor) and value.numel() == self.hparams.num_classes:\n",
    "                for i in range(self.hparams.num_classes):\n",
    "                    class_metric_name_for_csv = f\"{name}_{self.class_names[i]}\"\n",
    "                    current_metric_prog_bar_status = False\n",
    "                    if self.class_names[i] == \"cereal\":\n",
    "                        if name == \"val_jaccard_index_per_class\":\n",
    "                            prog_bar_name_override = \"val_iou_cereal\"\n",
    "                            current_metric_prog_bar_status = True\n",
    "                        elif name == \"val_f1_score_per_class\":\n",
    "                            prog_bar_name_override = \"val_f1_cereal\"\n",
    "                            current_metric_prog_bar_status = True\n",
    "                    if prog_bar_name_override and current_metric_prog_bar_status:\n",
    "                        self.log(prog_bar_name_override, value[i], prog_bar=True, logger=False, on_step=False, on_epoch=True, sync_dist=True)\n",
    "                        self.log(class_metric_name_for_csv, value[i], prog_bar=False, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n",
    "                        prog_bar_name_override = None\n",
    "                    else:\n",
    "                        self.log(class_metric_name_for_csv, value[i], prog_bar=False, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n",
    "            else:\n",
    "                if not (prog_bar_name_override and name.endswith(prog_bar_name_override.split('_')[-1])):\n",
    "                    self.log(name, value, prog_bar=log_to_prog_bar, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "        return optimizer\n",
    "\n",
    "CLASS_NAMES_FOR_LOGGING = [\"non_cereal\", \"cereal\"]\n",
    "lightning_model = None\n",
    "if 'task_config_obj' in locals() or 'task_config_obj' in globals():\n",
    "    lightning_model = LitSegmentationModel(\n",
    "        model_arch=task_config_obj.model, learning_rate=LR, weight_decay=WEIGHT_DECAY,\n",
    "        num_classes=NUM_CLASSES, class_names=CLASS_NAMES_FOR_LOGGING\n",
    "    )\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=LOGS_DIR_ACTUAL, name=\"cereal_segmentation_rand_aug_run\")\n",
    "\n",
    "loss_checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CHECKPOINT_SAVE_DIR_ACTUAL, filename='model-rand-aug-best-loss-{epoch:02d}-{val_loss:.3f}',\n",
    "    save_top_k=1, verbose=True, monitor='val_loss', mode='min'\n",
    ")\n",
    "iou_cereal_checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CHECKPOINT_SAVE_DIR_ACTUAL, filename='model-rand-aug-best-iou-cereal-{epoch:02d}-{val_jaccard_index_per_class_cereal:.3f}',\n",
    "    save_top_k=1, verbose=True, monitor='val_jaccard_index_per_class_cereal', mode='max'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=EARLY_STOPPING_MONITOR, patience=EARLY_STOPPING_PATIENCE, verbose=True,\n",
    "    mode=\"min\" if \"loss\" in EARLY_STOPPING_MONITOR.lower() else \"max\"\n",
    ")\n",
    "\n",
    "if lightning_model and train_loader:\n",
    "    is_interactive = False\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            is_interactive = True\n",
    "    except NameError:\n",
    "        is_interactive = False\n",
    "\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        strategy_to_use = \"ddp_notebook\" if is_interactive else \"ddp_find_unused_parameters_true\"\n",
    "    else:\n",
    "        strategy_to_use = \"auto\"\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"gpu\" if DEVICE == \"cuda\" else \"cpu\",\n",
    "        devices=\"auto\" if DEVICE == \"cuda\" else 1,\n",
    "        strategy=strategy_to_use,\n",
    "        num_nodes=1, max_epochs=EPOCHS, log_every_n_steps=10, logger=csv_logger,\n",
    "        callbacks=[early_stop_callback, loss_checkpoint_callback, iou_cereal_checkpoint_callback],\n",
    "        gradient_clip_val=0.5,\n",
    "    )\n",
    "    try:\n",
    "        val_dataloaders_arg = val_loader if val_loader and len(val_loader.dataset) > 0 else None\n",
    "        if not val_dataloaders_arg and EARLY_STOPPING_MONITOR.startswith(\"val_\"):\n",
    "            callbacks_list = [c for c in [loss_checkpoint_callback, iou_cereal_checkpoint_callback] if c.monitor is None or not c.monitor.startswith(\"val_\")]\n",
    "            if not EARLY_STOPPING_MONITOR.startswith(\"val_\"):\n",
    "                callbacks_list.append(early_stop_callback)\n",
    "            trainer.callbacks = callbacks_list\n",
    "\n",
    "        trainer.fit(lightning_model, train_dataloaders=train_loader, val_dataloaders=val_dataloaders_arg)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during training: {e}\")\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
