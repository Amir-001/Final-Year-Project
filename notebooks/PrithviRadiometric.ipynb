{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf457bd2-348f-455e-887b-a3cd2898ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, JaccardIndex\n",
    "from torchmetrics.collections import MetricCollection\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "from terratorch.tasks import SemanticSegmentationTask\n",
    "import rasterio\n",
    "import glob\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "# Cell 2: Configuration \n",
    "BASE_DATA_DIR_ACTUAL = \"<DATA_DIR>\"\n",
    "CHECKPOINT_SAVE_DIR_ACTUAL = \"<CHECKPOINT_DIR>\"\n",
    "LOGS_DIR_ACTUAL = \"<LOGS_DIR>\"\n",
    "\n",
    "PATCHES_DIR = os.path.join(BASE_DATA_DIR_ACTUAL, \"GEE_WeeklyPatches\")\n",
    "TARGETS_DIR = os.path.join(BASE_DATA_DIR_ACTUAL, \"GEE_WeeklyMasks\")\n",
    "\n",
    "os.makedirs(CHECKPOINT_SAVE_DIR_ACTUAL, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR_ACTUAL, exist_ok=True)\n",
    "\n",
    "EXPECTED_BANDS_ORDER = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\"]\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = 256\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "LR = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "HEAD_DROPOUT = 0.2\n",
    "FREEZE_BACKBONE = False\n",
    "\n",
    "BRIGHTNESS_RANGE = (0.95, 1.05)\n",
    "CONTRAST_RANGE = (0.95, 1.05)\n",
    "GAMMA_RANGE = (0.95, 1.05)\n",
    "GAUSSIAN_NOISE_STD = 0.0\n",
    "AUG_PROBABILITY = 0.3\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "EARLY_STOPPING_MONITOR = \"val_loss\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"PyTorch is available: {torch.cuda.is_available()} (CUDA)\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"CUDA available: {torch.cuda.device_count()} device(s) detected.\")\n",
    "\n",
    "# Cell 3: Custom Dataset Definition \n",
    "class CerealSensingDataset(Dataset):\n",
    "    def __init__(self, file_identifiers, patches_dir, targets_dir, target_img_size, \n",
    "                 augmentations=False, \n",
    "                 brightness_range=(1.0, 1.0), \n",
    "                 contrast_range=(1.0, 1.0),   \n",
    "                 gamma_range=(1.0, 1.0),      \n",
    "                 gaussian_noise_std=0.0,      \n",
    "                 aug_probability=0.5):\n",
    "        self.file_identifiers = file_identifiers\n",
    "        self.patches_dir = patches_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.target_img_size = target_img_size\n",
    "        self.augmentations = augmentations\n",
    "        self.brightness_range = brightness_range\n",
    "        self.contrast_range = contrast_range\n",
    "        self.gamma_range = gamma_range\n",
    "        self.gaussian_noise_std = gaussian_noise_std\n",
    "        self.aug_probability = aug_probability\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_identifiers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        identifier = self.file_identifiers[idx]\n",
    "        image_filename = f\"{identifier}_S2.tif\"\n",
    "        mask_filename = f\"{identifier}_Mask.tif\"\n",
    "        image_path = os.path.join(self.patches_dir, image_filename)\n",
    "        label_path = os.path.join(self.targets_dir, mask_filename)\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                image = src.read()\n",
    "                if image.shape[0] != 6:\n",
    "                    raise ValueError(f\"Image {identifier} has {image.shape[0]} bands, expected 6.\")\n",
    "            with rasterio.open(label_path) as src:\n",
    "                label = src.read(1)\n",
    "\n",
    "            image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "            label_tensor_float = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "            image_tensor = F.interpolate(image_tensor.unsqueeze(0),\n",
    "                                         size=(self.target_img_size, self.target_img_size),\n",
    "                                         mode='bilinear', align_corners=False).squeeze(0)\n",
    "            label_tensor_float = F.interpolate(label_tensor_float.unsqueeze(0).unsqueeze(0),\n",
    "                                         size=(self.target_img_size, self.target_img_size),\n",
    "                                         mode='nearest').squeeze(0).squeeze(0)\n",
    "\n",
    "            if self.augmentations:\n",
    "                num_channels = image_tensor.shape[0]\n",
    "\n",
    "                if random.random() < self.aug_probability:\n",
    "                    channel_to_aug = random.randint(0, num_channels - 1)\n",
    "                    brightness_factor = random.uniform(self.brightness_range[0], self.brightness_range[1])\n",
    "                    image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_brightness(\n",
    "                        image_tensor[channel_to_aug:channel_to_aug+1], brightness_factor\n",
    "                    )\n",
    "\n",
    "                if random.random() < self.aug_probability:\n",
    "                    channel_to_aug = random.randint(0, num_channels - 1)\n",
    "                    contrast_factor = random.uniform(self.contrast_range[0], self.contrast_range[1])\n",
    "                    image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_contrast(\n",
    "                        image_tensor[channel_to_aug:channel_to_aug+1], contrast_factor\n",
    "                    )\n",
    "\n",
    "                if random.random() < self.aug_probability:\n",
    "                    channel_to_aug = random.randint(0, num_channels - 1)\n",
    "                    gamma = random.uniform(self.gamma_range[0], self.gamma_range[1])\n",
    "                    gamma = max(0.1, gamma)\n",
    "                    channel_non_neg = torch.clamp(image_tensor[channel_to_aug:channel_to_aug+1], min=0)\n",
    "                    image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_gamma(\n",
    "                        channel_non_neg, gamma\n",
    "                    )\n",
    "\n",
    "                if self.gaussian_noise_std > 0 and random.random() < self.aug_probability:\n",
    "                    channel_to_aug = random.randint(0, num_channels - 1)\n",
    "                    noise = torch.randn_like(image_tensor[channel_to_aug]) * self.gaussian_noise_std\n",
    "                    image_tensor[channel_to_aug] = image_tensor[channel_to_aug] + noise\n",
    "\n",
    "                image_tensor = image_tensor.float()\n",
    "\n",
    "            label_tensor = label_tensor_float.long()\n",
    "\n",
    "            if image_tensor.shape != (6, self.target_img_size, self.target_img_size) or \\\n",
    "               label_tensor.shape != (self.target_img_size, self.target_img_size):\n",
    "                raise ValueError(f\"Shape mismatch for {identifier} post-processing. Img: {image_tensor.shape}, Lbl: {label_tensor.shape}\")\n",
    "            return image_tensor, label_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading/processing {identifier}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise e\n",
    "\n",
    "# Cell 4: Data Discovery, Integrity Check, Splitting and Loaders \n",
    "print(\"\\n=========== Data Loading & Prep ============\")\n",
    "image_files_pattern = os.path.join(PATCHES_DIR, \"Patch*_S2.tif\")\n",
    "all_image_filepaths = sorted(glob.glob(image_files_pattern))\n",
    "initial_file_identifiers = []\n",
    "if not all_image_filepaths: print(f\"ERROR: No image files found in {PATCHES_DIR}\")\n",
    "else: print(f\"Found {len(all_image_filepaths)} potential image files. Checking masks...\")\n",
    "for img_path in all_image_filepaths:\n",
    "    base_name = os.path.basename(img_path)\n",
    "    identifier_match = re.match(r\"(Patch\\d+_W\\d+_\\d{8})_S2\\.tif\", base_name)\n",
    "    if identifier_match:\n",
    "        identifier = identifier_match.group(1)\n",
    "        mask_path = os.path.join(TARGETS_DIR, f\"{identifier}_Mask.tif\")\n",
    "        if os.path.exists(mask_path): initial_file_identifiers.append(identifier)\n",
    "        else: print(f\"WARNING: Mask for {identifier} not found. Skipping.\")\n",
    "    else: print(f\"WARNING: Could not parse {base_name}. Skipping.\")\n",
    "print(f\"Found {len(initial_file_identifiers)} initial image-mask pairs.\")\n",
    "\n",
    "print(f\"\\nPerforming data integrity check on {len(initial_file_identifiers)} pairs...\")\n",
    "corrupted_identifiers, valid_identifiers = [], []\n",
    "if not initial_file_identifiers: print(\"No identifiers to check.\")\n",
    "else:\n",
    "    for identifier in initial_file_identifiers:\n",
    "        image_path = os.path.join(PATCHES_DIR, f\"{identifier}_S2.tif\")\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src: image_data = src.read()\n",
    "            problem, msgs = False, []\n",
    "            if np.isnan(image_data).any(): msgs.append(\"NaNs\"); problem = True\n",
    "            if image_data.max() > 65535 or image_data.min() < -32768 : \n",
    "                msgs.append(f\"Values out of typical sensor range (min: {image_data.min()}, max: {image_data.max()})\"); problem = True\n",
    "            if image_data.size > 0:\n",
    "                is_uniform_check = True\n",
    "                for band_idx_check in range(image_data.shape[0]):\n",
    "                    first_val_band_check = image_data[band_idx_check,0,0] if image_data.shape[1] > 0 and image_data.shape[2] > 0 else None\n",
    "                    if first_val_band_check is not None:\n",
    "                        if np.issubdtype(image_data[band_idx_check].dtype, np.floating):\n",
    "                            if not np.allclose(image_data[band_idx_check], first_val_band_check, atol=1e-5):\n",
    "                                is_uniform_check = False; break\n",
    "                        else:\n",
    "                            if not np.all(image_data[band_idx_check] == first_val_band_check):\n",
    "                                is_uniform_check = False; break\n",
    "                    elif image_data.shape[1] > 0 and image_data.shape[2] > 0 : \n",
    "                        is_uniform_check = False; break \n",
    "                if is_uniform_check and image_data.shape[1] > 0 and image_data.shape[2] > 0:\n",
    "                     msgs.append(f\"Uniform ({image_data[0,0,0]})\"); problem = True\n",
    "            else: msgs.append(\"Empty data\"); problem = True\n",
    "            if problem: print(f\"WARNING: {identifier} issues: {'; '.join(msgs)}. Skipping.\"); corrupted_identifiers.append(identifier)\n",
    "            else: valid_identifiers.append(identifier)\n",
    "        except Exception as e: print(f\"ERROR checking {identifier}: {e}. Skipping.\"); corrupted_identifiers.append(identifier)\n",
    "print(f\"Integrity check complete. Corrupted: {len(corrupted_identifiers)}.\")\n",
    "clean_identifiers = valid_identifiers\n",
    "num_clean_patches = len(clean_identifiers)\n",
    "print(f\"Clean patches: {num_clean_patches}\")\n",
    "\n",
    "train_ds, val_ds, train_loader, val_loader = None, None, None, None\n",
    "if num_clean_patches == 0: print(\"ERROR: No clean patches available.\")\n",
    "else:\n",
    "    random.shuffle(clean_identifiers)\n",
    "    if num_clean_patches >= 2:\n",
    "        num_train = max(1, int(num_clean_patches * 0.8))\n",
    "        train_ids, val_ids = clean_identifiers[:num_train], clean_identifiers[num_train:]\n",
    "        if not val_ids and len(train_ids) > 1: val_ids = [train_ids.pop()]\n",
    "        elif not val_ids and len(train_ids) == 1: print(\"WARNING: Only one sample available, cannot create val split.\")\n",
    "    elif num_clean_patches == 1:\n",
    "        train_ids, val_ids = clean_identifiers, []\n",
    "        print(\"WARNING: Only one sample. Training set has 1, validation is empty.\")\n",
    "    else: train_ids, val_ids = [], []\n",
    "    print(f\"Training IDs: {len(train_ids)}, Validation IDs: {len(val_ids)}\")\n",
    "\n",
    "    if train_ids:\n",
    "        train_ds = CerealSensingDataset(\n",
    "            train_ids, PATCHES_DIR, TARGETS_DIR, IMG_SIZE, \n",
    "            augmentations=True, \n",
    "            brightness_range=BRIGHTNESS_RANGE,\n",
    "            contrast_range=CONTRAST_RANGE,\n",
    "            gamma_range=GAMMA_RANGE,\n",
    "            gaussian_noise_std=GAUSSIAN_NOISE_STD,\n",
    "            aug_probability=AUG_PROBABILITY\n",
    "        )\n",
    "        num_data_workers = 4 \n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_data_workers, pin_memory=True if DEVICE==\"cuda\" else False, persistent_workers=True if num_data_workers > 0 else False)\n",
    "    else: print(\"ERROR: Training dataset empty.\")\n",
    "    if val_ids:\n",
    "        val_ds = CerealSensingDataset(val_ids, PATCHES_DIR, TARGETS_DIR, IMG_SIZE, augmentations=False) \n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_data_workers, pin_memory=True if DEVICE==\"cuda\" else False, persistent_workers=True if num_data_workers > 0 else False)\n",
    "    else: print(\"WARNING: Validation dataset empty.\")\n",
    "    if train_loader: print(f\"Train DataLoader created with {len(train_loader.dataset)} samples. Augmentations: True (Radiometric Only)\")\n",
    "    if val_loader: print(f\"Val DataLoader created with {len(val_loader.dataset)} samples. Augmentations: False\")\n",
    "    else: val_loader = None\n",
    "\n",
    "# Cell 5: Quick Visualisation (Sanity Check)\n",
    "if train_ds and len(train_ds) > 0:\n",
    "    try:\n",
    "        print(\"\\n--- Visualizing a sample from TRAIN_DS (potentially radiometrically augmented) ---\")\n",
    "        sample_img_aug, sample_mask_aug = train_ds[1] \n",
    "        print(f\"Augmented Sample Img Shape: {sample_img_aug.shape}, Mask Shape: {sample_mask_aug.shape}, Mask Unique: {torch.unique(sample_mask_aug)}\")\n",
    "        img_display_aug = sample_img_aug[:3].cpu().numpy()\n",
    "        img_min_aug, img_max_aug = img_display_aug.min(axis=(1,2),keepdims=True), img_display_aug.max(axis=(1,2),keepdims=True)\n",
    "        denominator_aug = img_max_aug - img_min_aug\n",
    "        denominator_aug[denominator_aug < 1e-6] = 1e-6\n",
    "        img_norm_aug = np.clip((img_display_aug - img_min_aug) / denominator_aug, 0, 1).transpose(1,2,0)\n",
    "        \n",
    "        fig_aug, axs_aug = plt.subplots(1,2, figsize=(10,5))\n",
    "        axs_aug[0].imshow(img_norm_aug); axs_aug[0].set_title(f'Augmented Input (ID: {train_ds.file_identifiers[0]})'); axs_aug[0].axis('off')\n",
    "        axs_aug[1].imshow(sample_mask_aug.cpu().numpy(), cmap='gray'); axs_aug[1].set_title('Corresponding Mask'); axs_aug[1].axis('off')\n",
    "        plt.tight_layout(); plt.show()\n",
    "    except Exception as e: print(f\"Visualization error for augmented sample: {e}\")\n",
    "else: print(\"Training dataset empty or not initialized. Skipping augmented sample visualization.\")\n",
    "\n",
    "# Cell 6: Load TerraTorch Model Configuration\n",
    "model_args = {\n",
    "    \"backbone\": \"prithvi_eo_v2_300\", \"backbone_pretrained\": True,\n",
    "    \"backbone_bands\": EXPECTED_BANDS_ORDER, \"decoder\": \"FCNDecoder\",\n",
    "    \"decoder_channels\": 256, \"head_dropout\": HEAD_DROPOUT,\n",
    "    \"num_classes\": NUM_CLASSES, \"rescale\": True\n",
    "}\n",
    "task_config_obj = SemanticSegmentationTask(\n",
    "    model_args=model_args, model_factory=\"EncoderDecoderFactory\", loss=\"ce\",\n",
    "    freeze_backbone=FREEZE_BACKBONE, lr=LR, optimizer=\"adamw\",\n",
    "    optimizer_hparams={\"weight_decay\": WEIGHT_DECAY}\n",
    ")\n",
    "print(f\"Backbone freezing: {FREEZE_BACKBONE}. Model configured for {len(EXPECTED_BANDS_ORDER)} bands.\")\n",
    "\n",
    "# Cell 7: PyTorch Lightning Module Definition\n",
    "class LitSegmentationModel(LightningModule):\n",
    "    def __init__(self, model_arch, learning_rate, weight_decay, num_classes, class_names=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model_arch'])\n",
    "        self.model = model_arch\n",
    "        self.class_weights_tensor = None \n",
    "        self.class_names = class_names if class_names else [f\"class{i}\" for i in range(num_classes)]\n",
    "\n",
    "        metrics = MetricCollection({\n",
    "            'accuracy_overall': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='micro'),\n",
    "            'precision_macro': Precision(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'recall_macro': Recall(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'f1_score_macro': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'jaccard_index_per_class': JaccardIndex(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'accuracy_per_class': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'precision_per_class': Precision(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'recall_per_class': Recall(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'f1_score_per_class': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "        })\n",
    "        self.val_metrics = metrics.clone(prefix='val_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out_struct = self.model(x)\n",
    "        logits = out_struct.output\n",
    "        weights = self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(logits, y, weight=weights)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out_struct = self.model(x)\n",
    "        logits = out_struct.output\n",
    "        weights = self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(logits, y, weight=weights)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True) \n",
    "        preds_classes = torch.argmax(logits, dim=1)\n",
    "        self.val_metrics.update(preds_classes, y)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics_output = self.val_metrics.compute()\n",
    "        for name, value in metrics_output.items():\n",
    "            log_to_prog_bar = False \n",
    "            prog_bar_name_override = None\n",
    "            if name in [\"val_accuracy_overall\", \"val_f1_score_macro\"]: log_to_prog_bar = True\n",
    "            if isinstance(value, torch.Tensor) and value.numel() == self.hparams.num_classes:\n",
    "                for i in range(self.hparams.num_classes):\n",
    "                    class_metric_name_for_csv = f\"{name}_{self.class_names[i]}\"\n",
    "                    current_metric_prog_bar_status = False\n",
    "                    if self.class_names[i] == \"cereal\": \n",
    "                        if name == \"val_jaccard_index_per_class\": prog_bar_name_override = \"val_iou_cereal\"; current_metric_prog_bar_status = True\n",
    "                        elif name == \"val_f1_score_per_class\": prog_bar_name_override = \"val_f1_cereal\"; current_metric_prog_bar_status = True\n",
    "                    if prog_bar_name_override and current_metric_prog_bar_status:\n",
    "                        self.log(prog_bar_name_override, value[i], prog_bar=True, logger=False, on_step=False, on_epoch=True, sync_dist=True)\n",
    "                        self.log(class_metric_name_for_csv, value[i], prog_bar=False, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n",
    "                        prog_bar_name_override = None \n",
    "                    else:\n",
    "                        self.log(class_metric_name_for_csv, value[i], prog_bar=False, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n",
    "            else: \n",
    "                if not (prog_bar_name_override and name.endswith(prog_bar_name_override.split('_')[-1])): \n",
    "                    self.log(name, value, prog_bar=log_to_prog_bar, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "        return optimizer\n",
    "\n",
    "CLASS_NAMES_FOR_LOGGING = [\"non_cereal\", \"cereal\"] \n",
    "lightning_model = None\n",
    "if 'task_config_obj' in locals() or 'task_config_obj' in globals():\n",
    "    lightning_model = LitSegmentationModel(\n",
    "        model_arch=task_config_obj.model, learning_rate=LR, weight_decay=WEIGHT_DECAY,\n",
    "        num_classes=NUM_CLASSES, class_names=CLASS_NAMES_FOR_LOGGING\n",
    "    )\n",
    "    print(\"LitSegmentationModel instantiated.\")\n",
    "else: print(\"ERROR: task_config_obj not defined.\")\n",
    "\n",
    "# Cell 8: Training\n",
    "csv_logger = CSVLogger(save_dir=LOGS_DIR_ACTUAL, name=\"cereal_segmentation_only_rad_aug_run\")\n",
    "print(f\"CSV logs will be saved in: {csv_logger.log_dir}\")\n",
    "\n",
    "loss_checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CHECKPOINT_SAVE_DIR_ACTUAL, filename='model-only-rad-aug-best-loss-{epoch:02d}-{val_loss:.3f}',\n",
    "    save_top_k=1, verbose=True, monitor='val_loss', mode='min'\n",
    ")\n",
    "iou_cereal_checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CHECKPOINT_SAVE_DIR_ACTUAL, filename='model-only-rad-aug-best-iou-cereal-{epoch:02d}-{val_jaccard_index_per_class_cereal:.3f}',\n",
    "    save_top_k=1, verbose=True, monitor='val_jaccard_index_per_class_cereal', mode='max'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=EARLY_STOPPING_MONITOR, patience=EARLY_STOPPING_PATIENCE, verbose=True,\n",
    "    mode=\"min\" if \"loss\" in EARLY_STOPPING_MONITOR.lower() else \"max\"\n",
    ")\n",
    "\n",
    "if lightning_model and train_loader: \n",
    "    is_interactive = False\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell': is_interactive = True\n",
    "    except NameError: is_interactive = False\n",
    "\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        strategy_to_use = \"ddp_notebook\" if is_interactive else \"ddp_find_unused_parameters_true\"\n",
    "        print(f\"INFO: Multiple GPUs detected. Using '{strategy_to_use}' strategy.\")\n",
    "    else:\n",
    "        strategy_to_use = \"auto\"\n",
    "        print(f\"INFO: Single GPU or CPU. Using '{strategy_to_use}' strategy.\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"gpu\" if DEVICE == \"cuda\" else \"cpu\",\n",
    "        devices=\"auto\" if DEVICE == \"cuda\" else 1, \n",
    "        strategy=strategy_to_use, \n",
    "        num_nodes=1, max_epochs=EPOCHS, log_every_n_steps=10, logger=csv_logger,    \n",
    "        callbacks=[early_stop_callback, loss_checkpoint_callback, iou_cereal_checkpoint_callback],\n",
    "        gradient_clip_val=0.5,\n",
    "    )\n",
    "    print(\"Starting training with ONLY radiometric augmentations...\")\n",
    "    try:\n",
    "        val_dataloaders_arg = val_loader if val_loader and len(val_loader.dataset) > 0 else None\n",
    "        if not val_dataloaders_arg and EARLY_STOPPING_MONITOR.startswith(\"val_\"):\n",
    "            print(f\"WARNING: val_loader is None/empty, but EarlyStopping monitors '{EARLY_STOPPING_MONITOR}'. Adjusting callbacks.\")\n",
    "            callbacks_list = [c for c in [loss_checkpoint_callback, iou_cereal_checkpoint_callback] if c.monitor is None or not c.monitor.startswith(\"val_\")]\n",
    "            if not EARLY_STOPPING_MONITOR.startswith(\"val_\"): callbacks_list.append(early_stop_callback)\n",
    "            else: print(\"EarlyStopping on validation metric removed as val_loader is absent.\")\n",
    "            trainer.callbacks = callbacks_list\n",
    "\n",
    "        trainer.fit(lightning_model, train_dataloaders=train_loader, val_dataloaders=val_dataloaders_arg)\n",
    "        print(\"Training finished.\")\n",
    "        if loss_checkpoint_callback.best_model_path: print(f\"Best model (by loss) saved at: {loss_checkpoint_callback.best_model_path}\")\n",
    "        if iou_cereal_checkpoint_callback.best_model_path: print(f\"Best model (by IoU for cereal) saved at: {iou_cereal_checkpoint_callback.best_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during training: {e}\"); traceback.print_exc()\n",
    "else:\n",
    "    print(\"ERROR: Training prerequisites not met (model or train_loader is None).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
