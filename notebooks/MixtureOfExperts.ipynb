{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b4117-cf3f-4323-a721-429263a386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, JaccardIndex\n",
    "from torchmetrics.collections import MetricCollection\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "from terratorch.tasks import SemanticSegmentationTask\n",
    "import satlaspretrain_models\n",
    "import rasterio\n",
    "import glob\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "print(\"--- MoE System Configuration ---\")\n",
    "\n",
    "# --- User-Specified / Cloud-Safe Paths (placeholders) ---\n",
    "MOE_CHECKPOINT_SAVE_DIR = \"checkpoints_moe\"\n",
    "MOE_LOGS_DIR = \"metrics_moe\"\n",
    "\n",
    "PRITHVI_CHECKPOINT_PATH = \"prithvi_checkpoint.ckpt\"\n",
    "SATLAS_CHECKPOINT_PATH = \"satlas_checkpoint.ckpt\"\n",
    "\n",
    "os.makedirs(MOE_CHECKPOINT_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(MOE_LOGS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"MoE Checkpoints will be saved to: {MOE_CHECKPOINT_SAVE_DIR}\")\n",
    "print(f\"MoE CSV Logs will be saved to: {MOE_LOGS_DIR}\")\n",
    "print(f\"Prithvi Expert Checkpoint: {PRITHVI_CHECKPOINT_PATH}\")\n",
    "print(f\"Satlas Expert Checkpoint: {SATLAS_CHECKPOINT_PATH}\")\n",
    "\n",
    "# --- Dataset Directories (Clean placeholders) ---\n",
    "BASE_DATA_DIR_ACTUAL = \"CerealDataset\"   # no absolute path\n",
    "PATCHES_DIR = f\"{BASE_DATA_DIR_ACTUAL}/GEE_WeeklyPatches\"\n",
    "TARGETS_DIR = f\"{BASE_DATA_DIR_ACTUAL}/GEE_WeeklyMasks\"\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# --- MoE Hyperparameters ---\n",
    "MOE_BATCH_SIZE = 1\n",
    "MOE_EPOCHS = 50\n",
    "MOE_LR = 1e-4\n",
    "MOE_WEIGHT_DECAY = 0.01\n",
    "MOE_RAND_AUGMENT_N = 2\n",
    "\n",
    "MOE_ROTATION_DEGREES = 180\n",
    "MOE_BRIGHTNESS_RANGE = (0.9, 1.1)\n",
    "MOE_CONTRAST_RANGE = (0.9, 1.1)\n",
    "MOE_GAMMA_RANGE = (0.9, 1.1)\n",
    "MOE_GAUSSIAN_NOISE_STD = 0.01\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"MoE Training Device: {DEVICE}\")\n",
    "\n",
    "CLASS_NAMES_FOR_LOGGING = [\"non_cereal\", \"cereal\"]\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 1: Configurations and Definitions from Prithvi Training Script\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Prithvi Configuration for Expert Loading ---\")\n",
    "PRITHVI_EXPECTED_BANDS_ORDER = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\"]\n",
    "PRITHVI_LR = 1e-5\n",
    "PRITHVI_WEIGHT_DECAY = 0.01\n",
    "PRITHVI_HEAD_DROPOUT = 0.2\n",
    "PRITHVI_FREEZE_BACKBONE = False\n",
    "\n",
    "prithvi_model_args_for_reconstruction = {\n",
    "    \"backbone\": \"prithvi_eo_v2_300\", \"backbone_pretrained\": False,\n",
    "    \"backbone_bands\": PRITHVI_EXPECTED_BANDS_ORDER, \"decoder\": \"FCNDecoder\",\n",
    "    \"decoder_channels\": 256, \"head_dropout\": PRITHVI_HEAD_DROPOUT,\n",
    "    \"num_classes\": NUM_CLASSES, \"rescale\": True\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: Configurations and Definitions from Satlas Training Script\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Satlas Configuration for Expert Loading & Input Mapping ---\")\n",
    "SATLAS_MODEL_IDENTIFIER = \"Sentinel2_SwinB_SI_MS\"\n",
    "MOE_INPUT_RAW_BANDS_ORDER = ['B2','B3','B4','B8','B11','B12'] \n",
    "MOE_INPUT_RAW_BAND_TO_IDX_MAP = {band_name: i for i, band_name in enumerate(MOE_INPUT_RAW_BANDS_ORDER)}\n",
    "\n",
    "SATLAS_EXPECTED_INPUT_CHANNEL_NAMES = [\n",
    "    \"TCI_R\", \"TCI_G\", \"TCI_B\", \"B05_duplicate\", \"B06_duplicate\", \"B07_duplicate\",\n",
    "    \"B08_from_B8\", \"B11\", \"B12\"\n",
    "]\n",
    "SATLAS_CHANNEL_TO_SOURCE_RAW_BAND_MAP = {\n",
    "    \"TCI_R\": \"B4\", \"TCI_G\": \"B3\", \"TCI_B\": \"B2\",\n",
    "    \"B05_duplicate\": \"B4\", \"B06_duplicate\": \"B3\", \"B07_duplicate\": \"B2\",\n",
    "    \"B08_from_B8\": \"B8\", \"B11\": \"B11\", \"B12\": \"B12\"\n",
    "}\n",
    "SATLAS_NORMALIZATION_DIVISOR = 8160.0\n",
    "SATLAS_LR = 1e-5\n",
    "SATLAS_WEIGHT_DECAY = 0.01\n",
    "SATLAS_FREEZE_BACKBONE_FPN = False\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 3: CerealSensingDataset_MoE\n",
    "# This dataset will output 6-channel images (MOE_INPUT_RAW_BANDS_ORDER)\n",
    "# ==============================================================================\n",
    "class CerealSensingDataset_MoE(Dataset):\n",
    "    def __init__(self, file_identifiers, patches_dir, targets_dir, target_img_size,\n",
    "                 raw_band_to_idx_map,  # For loading the 6 raw bands from GeoTIFF\n",
    "                 augmentations=False,\n",
    "                 rand_augment_n=0,\n",
    "                 rotation_degrees=0,\n",
    "                 brightness_range=(1.0, 1.0),\n",
    "                 contrast_range=(1.0, 1.0),\n",
    "                 gamma_range=(1.0, 1.0),\n",
    "                 gaussian_noise_std=0.0):\n",
    "        self.file_identifiers = file_identifiers\n",
    "        self.patches_dir = patches_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.target_img_size = target_img_size\n",
    "        self.raw_band_to_idx_map = raw_band_to_idx_map\n",
    "        self.num_raw_bands = len(raw_band_to_idx_map) # Should be 6 for MoE input\n",
    "\n",
    "        self.augmentations = augmentations\n",
    "        self.rand_augment_n = rand_augment_n\n",
    "\n",
    "        # Store parameters for individual operations\n",
    "        self.rotation_degrees = rotation_degrees\n",
    "        self.brightness_range = brightness_range\n",
    "        self.contrast_range = contrast_range\n",
    "        self.gamma_range = gamma_range\n",
    "        self.gaussian_noise_std = gaussian_noise_std\n",
    "\n",
    "        self.augmentation_pool = []\n",
    "        if self.augmentations and self.rand_augment_n > 0:\n",
    "            self._build_augmentation_pool()\n",
    "\n",
    "    # --- Helper methods for individual augmentations ---\n",
    "    def _aug_hflip(self, image_tensor, mask_tensor_float):\n",
    "        return TF.hflip(image_tensor), TF.hflip(mask_tensor_float)\n",
    "\n",
    "    def _aug_vflip(self, image_tensor, mask_tensor_float):\n",
    "        return TF.vflip(image_tensor), TF.vflip(mask_tensor_float)\n",
    "\n",
    "    def _aug_rotate(self, image_tensor, mask_tensor_float):\n",
    "        if self.rotation_degrees > 0:\n",
    "            angle = random.uniform(-self.rotation_degrees, self.rotation_degrees)\n",
    "            image_tensor = TF.rotate(image_tensor, angle, interpolation=TF.InterpolationMode.BILINEAR)\n",
    "            # Mask needs to be [C, H, W] for rotate, typically [1, H, W]\n",
    "            if mask_tensor_float.ndim == 2: mask_tensor_float = mask_tensor_float.unsqueeze(0)\n",
    "            mask_tensor_float = TF.rotate(mask_tensor_float, angle, interpolation=TF.InterpolationMode.NEAREST)\n",
    "            if mask_tensor_float.ndim == 3 and mask_tensor_float.shape[0] == 1: mask_tensor_float = mask_tensor_float.squeeze(0)\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_brightness_single_channel(self, image_tensor, mask_tensor_float):\n",
    "        num_channels = image_tensor.shape[0] # Should be 6 for MoE input\n",
    "        if num_channels > 0:\n",
    "            channel_to_aug = random.randint(0, num_channels - 1)\n",
    "            factor = random.uniform(self.brightness_range[0], self.brightness_range[1])\n",
    "            image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_brightness(\n",
    "                image_tensor[channel_to_aug:channel_to_aug+1], factor\n",
    "            )\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_contrast_single_channel(self, image_tensor, mask_tensor_float):\n",
    "        num_channels = image_tensor.shape[0]\n",
    "        if num_channels > 0:\n",
    "            channel_to_aug = random.randint(0, num_channels - 1)\n",
    "            factor = random.uniform(self.contrast_range[0], self.contrast_range[1])\n",
    "            image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_contrast(\n",
    "                image_tensor[channel_to_aug:channel_to_aug+1], factor\n",
    "            )\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_gamma_single_channel(self, image_tensor, mask_tensor_float):\n",
    "        num_channels = image_tensor.shape[0]\n",
    "        if num_channels > 0:\n",
    "            channel_to_aug = random.randint(0, num_channels - 1)\n",
    "            gamma = random.uniform(self.gamma_range[0], self.gamma_range[1])\n",
    "            gamma = max(0.1, gamma)\n",
    "            # Ensure channel is non-negative for gamma correction. Input is raw, might be negative.\n",
    "            channel_slice = image_tensor[channel_to_aug:channel_to_aug+1]\n",
    "            channel_non_neg = torch.clamp(channel_slice, min=0)\n",
    "            image_tensor[channel_to_aug:channel_to_aug+1] = TF.adjust_gamma(channel_non_neg, gamma)\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _aug_gaussian_noise_all_channels(self, image_tensor, mask_tensor_float):\n",
    "        if self.gaussian_noise_std > 0:\n",
    "            noise = torch.randn_like(image_tensor) * self.gaussian_noise_std\n",
    "            image_tensor = image_tensor + noise\n",
    "        return image_tensor, mask_tensor_float\n",
    "\n",
    "    def _build_augmentation_pool(self):\n",
    "        self.augmentation_pool = []\n",
    "        # Geometric\n",
    "        self.augmentation_pool.append(self._aug_hflip)\n",
    "        self.augmentation_pool.append(self._aug_vflip)\n",
    "        if self.rotation_degrees > 0: self.augmentation_pool.append(self._aug_rotate)\n",
    "        # Photometric (applied to one of the 6 raw bands)\n",
    "        self.augmentation_pool.append(self._aug_brightness_single_channel)\n",
    "        self.augmentation_pool.append(self._aug_contrast_single_channel)\n",
    "        self.augmentation_pool.append(self._aug_gamma_single_channel)\n",
    "        if self.gaussian_noise_std > 0:\n",
    "            self.augmentation_pool.append(self._aug_gaussian_noise_all_channels)\n",
    "        if not self.augmentation_pool:\n",
    "             print(\"Note: Augmentation pool is empty based on current settings.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_identifiers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        identifier = self.file_identifiers[idx]\n",
    "        image_filename = f\"{identifier}_S2.tif\"\n",
    "        mask_filename = f\"{identifier}_Mask.tif\"\n",
    "        image_path = os.path.join(self.patches_dir, image_filename)\n",
    "        label_path = os.path.join(self.targets_dir, mask_filename)\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                all_bands_data = src.read()\n",
    "                if all_bands_data.shape[0] < self.num_raw_bands:\n",
    "                    raise ValueError(f\"Image {identifier} has {all_bands_data.shape[0]} bands, expected at least {self.num_raw_bands}.\")\n",
    "                # Select the 6 channels for MoE based on MOE_INPUT_RAW_BANDS_ORDER and the map\n",
    "                image_6_channel_data = all_bands_data[[self.raw_band_to_idx_map[bname] for bname in MOE_INPUT_RAW_BANDS_ORDER], :, :]\n",
    "\n",
    "            with rasterio.open(label_path) as src:\n",
    "                label = src.read(1)\n",
    "\n",
    "            image_tensor = torch.tensor(image_6_channel_data, dtype=torch.float32)\n",
    "            label_tensor_float = torch.tensor(label, dtype=torch.float32) # Keep as float for interpolation and aug\n",
    "\n",
    "            # Resize\n",
    "            image_tensor = F.interpolate(image_tensor.unsqueeze(0),\n",
    "                                         size=(self.target_img_size, self.target_img_size),\n",
    "                                         mode='bilinear', align_corners=False).squeeze(0)\n",
    "            \n",
    "            # Ensure label_tensor_float is [H, W] before potential unsqueeze in aug\n",
    "            label_tensor_float = F.interpolate(label_tensor_float.unsqueeze(0).unsqueeze(0),\n",
    "                                             size=(self.target_img_size, self.target_img_size),\n",
    "                                             mode='nearest').squeeze(0).squeeze(0)\n",
    "\n",
    "\n",
    "            # Apply RandAugment-like strategy\n",
    "            if self.augmentations and self.rand_augment_n > 0 and self.augmentation_pool:\n",
    "                num_ops_to_apply = min(self.rand_augment_n, len(self.augmentation_pool))\n",
    "                ops_to_apply = random.sample(self.augmentation_pool, num_ops_to_apply)\n",
    "                \n",
    "                # Ensure mask is float and potentially [1, H, W] for aug functions that might expect channel dim\n",
    "                current_mask_for_aug = label_tensor_float\n",
    "                if current_mask_for_aug.ndim == 2: \n",
    "                    current_mask_for_aug = current_mask_for_aug.unsqueeze(0) \n",
    "\n",
    "                for op_func in ops_to_apply:\n",
    "                    image_tensor, current_mask_for_aug = op_func(image_tensor, current_mask_for_aug)\n",
    "                \n",
    "                # Ensure mask is back to [H,W] if it was unsqueezed\n",
    "                if current_mask_for_aug.ndim == 3 and current_mask_for_aug.shape[0] == 1:\n",
    "                    label_tensor_float = current_mask_for_aug.squeeze(0)\n",
    "                else: # Should already be [H,W] if ops returned it that way\n",
    "                    label_tensor_float = current_mask_for_aug\n",
    "\n",
    "\n",
    "            label_tensor = label_tensor_float.long()\n",
    "\n",
    "            # This dataset outputs the 6-channel image directly.\n",
    "            # Normalization specific to Satlas will happen later in the MoESegmentationSystem.\n",
    "            return image_tensor, label_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"Error in CerealSensingDataset_MoE for {identifier}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise e\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 4: LitSegmentationModel Definition \n",
    "# ==============================================================================\n",
    "class LitSegmentationModel(LightningModule):\n",
    "    def __init__(self, model_arch=None, full_satlas_model=None,\n",
    "                 learning_rate=1e-5, weight_decay=0.01, \n",
    "                 num_classes=2, class_names=None, freeze_backbone_fpn=False): \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model_arch', 'full_satlas_model'])\n",
    "        \n",
    "        if full_satlas_model is not None:\n",
    "            self.model = full_satlas_model\n",
    "            if freeze_backbone_fpn: \n",
    "                frozen_count = 0\n",
    "                if hasattr(self.model, 'backbone'):\n",
    "                    for param in self.model.backbone.parameters(): param.requires_grad = False\n",
    "                    print(\"Satlas backbone parameters frozen during LitModel init.\")\n",
    "                    frozen_count +=1\n",
    "                if hasattr(self.model, 'fpn'):\n",
    "                    for param in self.model.fpn.parameters(): param.requires_grad = False\n",
    "                    print(\"Satlas FPN parameters frozen during LitModel init.\")\n",
    "                    frozen_count +=1\n",
    "                if frozen_count == 0: print(\"WARNING: Could not find 'backbone' or 'fpn' in full_satlas_model to freeze.\")\n",
    "        elif model_arch is not None:\n",
    "            self.model = model_arch\n",
    "        else:\n",
    "            raise ValueError(\"Either model_arch (for Prithvi-like) or full_satlas_model must be provided.\")\n",
    "\n",
    "        self.class_weights_tensor = None\n",
    "        self.class_names = class_names if class_names else [f\"class_{i}\" for i in range(num_classes)]\n",
    "        \n",
    "        metrics_to_clone = MetricCollection({\n",
    "            'accuracy_overall': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='micro'),\n",
    "            'f1_score_macro': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'jaccard_index_macro': JaccardIndex(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'), # For overall IoU\n",
    "            'jaccard_index_per_class': JaccardIndex(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'accuracy_per_class': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'f1_score_per_class': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none')\n",
    "        })\n",
    "        self.val_metrics = metrics_to_clone.clone(prefix='val_')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_output = self.model(x)\n",
    "        if isinstance(model_output, tuple): \n",
    "            logits = model_output[0]\n",
    "        elif hasattr(model_output, 'output'): \n",
    "            logits = model_output.output\n",
    "        else: \n",
    "            logits = model_output\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch; logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y, weight=(self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None))\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True); return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch; logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y, weight=(self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None))\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True, sync_dist=True); \n",
    "        self.val_metrics.update(torch.argmax(logits, dim=1), y); \n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics_output = self.val_metrics.compute()\n",
    "        for name, value in metrics_output.items():\n",
    "            is_prog_bar = name in [\"val_f1_score_macro\", \"val_jaccard_index_macro\", \"val_accuracy_overall\"]\n",
    "            if isinstance(value, torch.Tensor) and value.numel() == self.hparams.num_classes:\n",
    "                for i in range(self.hparams.num_classes):\n",
    "                    class_metric_name = f\"{name}_{self.class_names[i]}\"\n",
    "                    prog_bar_metric_name, log_to_prog_bar_specific = None, False\n",
    "                    if self.class_names[i] == \"cereal\":\n",
    "                        if name == \"val_jaccard_index_per_class\": prog_bar_metric_name, log_to_prog_bar_specific = \"val_iou_cereal\", True\n",
    "                        elif name == \"val_f1_score_per_class\": prog_bar_metric_name, log_to_prog_bar_specific = \"val_f1_cereal\", True\n",
    "                    \n",
    "                    if prog_bar_metric_name and log_to_prog_bar_specific:\n",
    "                        self.log(prog_bar_metric_name, value[i], prog_bar=True, logger=False, sync_dist=True)\n",
    "                        self.log(class_metric_name, value[i], prog_bar=False, logger=True, sync_dist=True)\n",
    "                    else:\n",
    "                        self.log(class_metric_name, value[i], prog_bar=False, logger=True, sync_dist=True)\n",
    "            else:\n",
    "                self.log(name, value, prog_bar=is_prog_bar, logger=True, sync_dist=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 5: Helper Functions to Load Expert Models \n",
    "# ==============================================================================\n",
    "def load_prithvi_expert(checkpoint_path, model_args_for_recon, device):\n",
    "    print(f\"Loading Prithvi expert from: {checkpoint_path}\")\n",
    "    prithvi_task_for_arch = SemanticSegmentationTask(\n",
    "        model_args=model_args_for_recon, model_factory=\"EncoderDecoderFactory\",\n",
    "        loss=\"ce\", lr=1e-5, optimizer=\"adamw\"\n",
    "    )\n",
    "    prithvi_architecture_nn_module = prithvi_task_for_arch.model\n",
    "    loaded_lit_model = LitSegmentationModel.load_from_checkpoint(\n",
    "        checkpoint_path, map_location=torch.device('cpu'),\n",
    "        model_arch=prithvi_architecture_nn_module, learning_rate=PRITHVI_LR, \n",
    "        weight_decay=PRITHVI_WEIGHT_DECAY, num_classes=NUM_CLASSES,\n",
    "        class_names=CLASS_NAMES_FOR_LOGGING\n",
    "    )\n",
    "    expert_model = loaded_lit_model.model\n",
    "    expert_model.eval()\n",
    "    for param in expert_model.parameters(): param.requires_grad = False\n",
    "    print(\"Prithvi expert model loaded, set to eval, and frozen.\")\n",
    "    return expert_model.to(device)\n",
    "\n",
    "def load_satlas_expert(checkpoint_path, satlas_model_id, num_seg_classes, device):\n",
    "    print(f\"Loading Satlas expert from: {checkpoint_path}\")\n",
    "    try:\n",
    "        weights_manager = satlaspretrain_models.Weights()\n",
    "        satlas_architecture_nn_module = weights_manager.get_pretrained_model(\n",
    "            model_identifier=satlas_model_id, fpn=True,\n",
    "            head=satlaspretrain_models.Head.SEGMENT, num_categories=num_seg_classes\n",
    "        )\n",
    "        print(f\"Base Satlas architecture '{satlas_model_id}' with segmentation head loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error instantiating base Satlas architecture: {e}\"); traceback.print_exc(); return None\n",
    "    \n",
    "    loaded_lit_model = LitSegmentationModel.load_from_checkpoint(\n",
    "        checkpoint_path, map_location=torch.device('cpu'),\n",
    "        full_satlas_model=satlas_architecture_nn_module, learning_rate=SATLAS_LR,\n",
    "        weight_decay=SATLAS_WEIGHT_DECAY, num_classes=NUM_CLASSES,\n",
    "        class_names=CLASS_NAMES_FOR_LOGGING, freeze_backbone_fpn=False \n",
    "    )\n",
    "    expert_model = loaded_lit_model.model\n",
    "    expert_model.eval()\n",
    "    for param in expert_model.parameters(): param.requires_grad = False\n",
    "    print(\"Satlas expert model loaded, set to eval, and frozen.\")\n",
    "    return expert_model.to(device)\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 6: Gating Network Definition \n",
    "# ==============================================================================\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_channels, num_experts):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(32, num_experts)\n",
    "\n",
    "    def forward(self, x): # x is [B, 6, H, W]\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        expert_logits = self.fc(x)\n",
    "        expert_weights = F.softmax(expert_logits, dim=1) # [B, num_experts]\n",
    "        return expert_weights\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 7: MoE LightningModule Definition \n",
    "# ==============================================================================\n",
    "class MoESegmentationSystem(LightningModule):\n",
    "    def __init__(self, prithvi_expert_nn_module, satlas_expert_nn_module,\n",
    "                 moe_input_raw_band_to_idx_map, \n",
    "                 satlas_expected_input_channel_names, \n",
    "                 satlas_channel_to_source_raw_band_map,\n",
    "                 satlas_normalization_divisor,\n",
    "                 num_moe_input_channels, \n",
    "                 num_output_classes, \n",
    "                 learning_rate, weight_decay, class_names=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['prithvi_expert_nn_module', 'satlas_expert_nn_module'])\n",
    "\n",
    "        self.prithvi_expert = prithvi_expert_nn_module\n",
    "        self.satlas_expert = satlas_expert_nn_module\n",
    "        \n",
    "        self.gating_network = GatingNetwork(input_channels=num_moe_input_channels, num_experts=2)\n",
    "\n",
    "        self.moe_input_raw_band_to_idx_map = moe_input_raw_band_to_idx_map\n",
    "        self.satlas_expected_input_channel_names = satlas_expected_input_channel_names\n",
    "        self.satlas_channel_to_source_raw_band_map = satlas_channel_to_source_raw_band_map\n",
    "        self.satlas_normalization_divisor = satlas_normalization_divisor\n",
    "        \n",
    "        self.class_names = class_names if class_names else [f\"class{i}\" for i in range(num_output_classes)]\n",
    "        self.class_weights_tensor = None\n",
    "\n",
    "        moe_metrics = MetricCollection({\n",
    "            'accuracy_overall': Accuracy(task=\"multiclass\", num_classes=num_output_classes, average='micro'),\n",
    "            'precision_macro': Precision(task=\"multiclass\", num_classes=num_output_classes, average='macro'),\n",
    "            'recall_macro': Recall(task=\"multiclass\", num_classes=num_output_classes, average='macro'),\n",
    "            'f1_score_macro': F1Score(task=\"multiclass\", num_classes=num_output_classes, average='macro'),\n",
    "            'jaccard_index_macro': JaccardIndex(task=\"multiclass\", num_classes=num_output_classes, average='macro'),\n",
    "            'accuracy_per_class': Accuracy(task=\"multiclass\", num_classes=num_output_classes, average='none'),\n",
    "            'precision_per_class': Precision(task=\"multiclass\", num_classes=num_output_classes, average='none'),\n",
    "            'recall_per_class': Recall(task=\"multiclass\", num_classes=num_output_classes, average='none'),\n",
    "            'f1_score_per_class': F1Score(task=\"multiclass\", num_classes=num_output_classes, average='none'),\n",
    "            'jaccard_index_per_class': JaccardIndex(task=\"multiclass\", num_classes=num_output_classes, average='none')\n",
    "        })\n",
    "        self.val_moe_metrics = moe_metrics.clone(prefix='val_moe_')\n",
    "\n",
    "    def _map_input_to_satlas_format(self, x_6_channel_raw): \n",
    "        batch_size, _, height, width = x_6_channel_raw.shape\n",
    "        device = x_6_channel_raw.device\n",
    "        \n",
    "        satlas_input_bands_list = []\n",
    "        for target_satlas_channel_name in self.satlas_expected_input_channel_names:\n",
    "            source_raw_band_name = self.satlas_channel_to_source_raw_band_map[target_satlas_channel_name]\n",
    "            raw_band_idx_in_6_channel_input = self.moe_input_raw_band_to_idx_map[source_raw_band_name]\n",
    "            selected_band = x_6_channel_raw[:, raw_band_idx_in_6_channel_input, :, :]\n",
    "            satlas_input_bands_list.append(selected_band)\n",
    "            \n",
    "        x_9_channel_for_satlas = torch.stack(satlas_input_bands_list, dim=1)\n",
    "        x_9_channel_for_satlas_normalized = x_9_channel_for_satlas / self.satlas_normalization_divisor\n",
    "        x_9_channel_for_satlas_normalized = torch.clip(x_9_channel_for_satlas_normalized, 0.0, 1.0)\n",
    "        return x_9_channel_for_satlas_normalized\n",
    "\n",
    "    def forward(self, x_raw_6_channel):\n",
    "        gate_weights = self.gating_network(x_raw_6_channel)\n",
    "        prithvi_struct = self.prithvi_expert(x_raw_6_channel)\n",
    "        logits_prithvi = prithvi_struct.output\n",
    "        x_for_satlas = self._map_input_to_satlas_format(x_raw_6_channel)\n",
    "        satlas_output = self.satlas_expert(x_for_satlas)\n",
    "        logits_satlas = satlas_output[0] if isinstance(satlas_output, tuple) else satlas_output\n",
    "        \n",
    "        w_prithvi = gate_weights[:, 0].view(-1, 1, 1, 1) \n",
    "        w_satlas = gate_weights[:, 1].view(-1, 1, 1, 1)  \n",
    "        final_logits = w_prithvi * logits_prithvi + w_satlas * logits_satlas\n",
    "        return final_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        final_logits = self.forward(x)\n",
    "        weights = self.class_weights_tensor.to(final_logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(final_logits, y, weight=weights)\n",
    "        self.log(\"train_moe_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        final_logits = self.forward(x)\n",
    "        weights = self.class_weights_tensor.to(final_logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(final_logits, y, weight=weights)\n",
    "        self.log(\"val_moe_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        preds_classes = torch.argmax(final_logits, dim=1)\n",
    "        self.val_moe_metrics.update(preds_classes, y)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics_output = self.val_moe_metrics.compute()\n",
    "        for name, value in metrics_output.items():\n",
    "            if isinstance(value, torch.Tensor) and value.numel() == self.hparams.num_output_classes:\n",
    "                for i in range(self.hparams.num_output_classes):\n",
    "                    class_metric_name = f\"{name}_{self.class_names[i]}\"\n",
    "                    current_metric_prog_bar_flag = False\n",
    "                    if self.class_names[i] == \"cereal\":\n",
    "                        if \"jaccard_index_per_class\" in name: current_metric_prog_bar_flag = True\n",
    "                    self.log(class_metric_name, value[i], \n",
    "                             on_step=False, on_epoch=True, \n",
    "                             prog_bar=current_metric_prog_bar_flag, \n",
    "                             logger=True, sync_dist=True)\n",
    "            else:\n",
    "                current_metric_prog_bar_flag = name in [\"val_moe_accuracy_overall\", \"val_moe_f1_score_macro\", \"val_moe_jaccard_index_macro\"]\n",
    "                self.log(name, value, \n",
    "                         on_step=False, on_epoch=True, \n",
    "                         prog_bar=current_metric_prog_bar_flag, \n",
    "                         logger=True, sync_dist=True)\n",
    "        self.val_moe_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.gating_network.parameters(), \n",
    "                                      lr=self.hparams.learning_rate, \n",
    "                                      weight_decay=self.hparams.weight_decay)\n",
    "        return optimizer\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 8: Main Execution Block for MoE Training \n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- Initializing MoE System ---\")\n",
    "\n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # --- 1. Load Prithvi Expert ---\n",
    "    prithvi_expert = load_prithvi_expert(PRITHVI_CHECKPOINT_PATH, prithvi_model_args_for_reconstruction, DEVICE)\n",
    "    if prithvi_expert is None: print(\"CRITICAL ERROR: Failed to load Prithvi expert. Exiting.\"); exit()\n",
    "\n",
    "    # --- 2. Load Satlas Expert ---\n",
    "    satlas_expert = load_satlas_expert(SATLAS_CHECKPOINT_PATH, SATLAS_MODEL_IDENTIFIER, NUM_CLASSES, DEVICE)\n",
    "    if satlas_expert is None: print(\"CRITICAL ERROR: Failed to load Satlas expert. Exiting.\"); exit()\n",
    "\n",
    "    # --- 3. Instantiate MoE System ---\n",
    "    moe_lightning_system = MoESegmentationSystem(\n",
    "        prithvi_expert_nn_module=prithvi_expert, satlas_expert_nn_module=satlas_expert,\n",
    "        moe_input_raw_band_to_idx_map=MOE_INPUT_RAW_BAND_TO_IDX_MAP,\n",
    "        satlas_expected_input_channel_names=SATLAS_EXPECTED_INPUT_CHANNEL_NAMES,\n",
    "        satlas_channel_to_source_raw_band_map=SATLAS_CHANNEL_TO_SOURCE_RAW_BAND_MAP,\n",
    "        satlas_normalization_divisor=SATLAS_NORMALIZATION_DIVISOR,\n",
    "        num_moe_input_channels=len(MOE_INPUT_RAW_BANDS_ORDER),\n",
    "        num_output_classes=NUM_CLASSES, learning_rate=MOE_LR,\n",
    "        weight_decay=MOE_WEIGHT_DECAY, class_names=CLASS_NAMES_FOR_LOGGING\n",
    "    )\n",
    "    print(\"MoESegmentationSystem instantiated.\")\n",
    "\n",
    "    # --- 4. Setup DataLoaders for MoE training ---\n",
    "    print(\"\\n--- MoE Data Preparation ---\")\n",
    "    \n",
    "    # --- Initial Data Discovery ---\n",
    "    moe_image_files_pattern = os.path.join(PATCHES_DIR, \"Patch*_S2.tif\")\n",
    "    moe_all_image_filepaths = sorted(glob.glob(moe_image_files_pattern))\n",
    "    initial_moe_identifiers = []\n",
    "    \n",
    "    if not moe_all_image_filepaths: print(f\"ERROR: No image files found with pattern {moe_image_files_pattern}\"); exit()\n",
    "    else: print(f\"Found {len(moe_all_image_filepaths)} potential images. Checking masks...\")\n",
    "\n",
    "    for img_path in moe_all_image_filepaths:\n",
    "        base_name = os.path.basename(img_path)\n",
    "        identifier_match = re.match(r\"(Patch\\d+_W\\d+_\\d{8})_S2\\.tif\", base_name)\n",
    "        if identifier_match:\n",
    "            identifier = identifier_match.group(1)\n",
    "            mask_path = os.path.join(TARGETS_DIR, f\"{identifier}_Mask.tif\")\n",
    "            if os.path.exists(mask_path): initial_moe_identifiers.append(identifier)\n",
    "            else: print(f\"WARNING: Mask for {identifier} not found. Skipping.\")\n",
    "        else: print(f\"WARNING: Could not parse {base_name}. Skipping.\")\n",
    "    \n",
    "    if not initial_moe_identifiers: print(\"ERROR: No image-mask pairs found. Exiting.\"); exit()\n",
    "    print(f\"Found {len(initial_moe_identifiers)} initial image-mask pairs.\")\n",
    "\n",
    "    # --- Data Integrity Check ---\n",
    "    print(f\"\\nPerforming data integrity check on {len(initial_moe_identifiers)} pairs...\")\n",
    "    corrupted_identifiers, clean_moe_identifiers = [], []\n",
    "    num_bands_expected_in_raw_file = len(MOE_INPUT_RAW_BANDS_ORDER)\n",
    "\n",
    "    for identifier in initial_moe_identifiers:\n",
    "        image_path = os.path.join(PATCHES_DIR, f\"{identifier}_S2.tif\")\n",
    "        problem, msgs = False, []\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                if src.count < num_bands_expected_in_raw_file:\n",
    "                    msgs.append(f\"File has {src.count} bands, expected {num_bands_expected_in_raw_file}.\"); problem = True\n",
    "                else:\n",
    "                    indices_to_read = [MOE_INPUT_RAW_BAND_TO_IDX_MAP[b_name] for b_name in MOE_INPUT_RAW_BANDS_ORDER]\n",
    "                    if any(idx >= src.count for idx in indices_to_read):\n",
    "                        msgs.append(f\"Band indices out of range for file with {src.count} bands.\"); problem = True\n",
    "                    else:\n",
    "                        bands_to_read_1_indexed = [idx + 1 for idx in indices_to_read]\n",
    "                        data_to_check = src.read(bands_to_read_1_indexed).astype(np.float32)\n",
    "                        if data_to_check.shape[0] != num_bands_expected_in_raw_file:\n",
    "                            msgs.append(f\"Read {data_to_check.shape[0]} bands, expected {num_bands_expected_in_raw_file}.\"); problem = True\n",
    "                        if np.isnan(data_to_check).any(): msgs.append(\"NaNs found.\"); problem = True\n",
    "                        if data_to_check.min() < -2000: msgs.append(f\"Low values: {data_to_check.min()}.\"); problem = True\n",
    "                        if data_to_check.max() > 20000: msgs.append(f\"High values: {data_to_check.max()}.\"); problem = True\n",
    "                        if data_to_check.size > 0 and not problem:\n",
    "                            is_uniform_issue = False\n",
    "                            for i in range(data_to_check.shape[0]):\n",
    "                                band_data = data_to_check[i]\n",
    "                                if band_data.size > 0 and np.allclose(band_data, band_data.flat[0], atol=1e-1):\n",
    "                                    msgs.append(f\"Band {MOE_INPUT_RAW_BANDS_ORDER[i]} uniform.\"); is_uniform_issue = True; break\n",
    "                            if is_uniform_issue: problem = True\n",
    "                        elif data_to_check.size == 0: msgs.append(\"Empty data read.\"); problem = True\n",
    "            if problem:\n",
    "                print(f\"WARNING: {identifier} issues: {'; '.join(msgs)}. Skipping.\")\n",
    "                corrupted_identifiers.append(identifier)\n",
    "            else:\n",
    "                clean_moe_identifiers.append(identifier)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR checking {identifier}: {e}. Skipping.\"); corrupted_identifiers.append(identifier)\n",
    "            traceback.print_exc()\n",
    "\n",
    "    print(f\"Integrity check done. Corrupted: {len(corrupted_identifiers)}. Valid: {len(clean_moe_identifiers)}.\")\n",
    "    if not clean_moe_identifiers: print(\"ERROR: No clean image-mask pairs after integrity check. Exiting.\"); exit()\n",
    "\n",
    "    random.shuffle(clean_moe_identifiers)\n",
    "    moe_split_idx = int(len(clean_moe_identifiers) * 0.8)\n",
    "    moe_train_ids = clean_moe_identifiers[:moe_split_idx]\n",
    "    moe_val_ids = clean_moe_identifiers[moe_split_idx:]\n",
    "\n",
    "    if not moe_train_ids: print(\"ERROR: MoE training set empty. Exiting.\"); exit()\n",
    "\n",
    "    moe_train_ds = CerealSensingDataset_MoE(\n",
    "        file_identifiers=moe_train_ids,\n",
    "        patches_dir=PATCHES_DIR, targets_dir=TARGETS_DIR, target_img_size=IMG_SIZE,\n",
    "        raw_band_to_idx_map=MOE_INPUT_RAW_BAND_TO_IDX_MAP,\n",
    "        augmentations=True, # Master switch for augmentations\n",
    "        rand_augment_n=MOE_RAND_AUGMENT_N,\n",
    "        rotation_degrees=MOE_ROTATION_DEGREES,\n",
    "        brightness_range=MOE_BRIGHTNESS_RANGE,\n",
    "        contrast_range=MOE_CONTRAST_RANGE,\n",
    "        gamma_range=MOE_GAMMA_RANGE,\n",
    "        gaussian_noise_std=MOE_GAUSSIAN_NOISE_STD\n",
    "    )\n",
    "    moe_train_loader = DataLoader(moe_train_ds, batch_size=MOE_BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "    print(f\"MoE Train DataLoader: {len(moe_train_loader.dataset)} samples. Augmentations: RandAugment-like (N={MOE_RAND_AUGMENT_N})\")\n",
    "\n",
    "    moe_val_loader = None\n",
    "    if moe_val_ids:\n",
    "        moe_val_ds = CerealSensingDataset_MoE(\n",
    "            file_identifiers=moe_val_ids,\n",
    "            patches_dir=PATCHES_DIR, targets_dir=TARGETS_DIR, target_img_size=IMG_SIZE,\n",
    "            raw_band_to_idx_map=MOE_INPUT_RAW_BAND_TO_IDX_MAP,\n",
    "            augmentations=False # No augmentations for validation set\n",
    "        )\n",
    "        moe_val_loader = DataLoader(moe_val_ds, batch_size=MOE_BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "        print(f\"MoE Val DataLoader: {len(moe_val_loader.dataset)} samples.\")\n",
    "    else:\n",
    "        print(\"WARNING: MoE Validation dataset is empty.\")\n",
    "\n",
    "    # --- 5. Setup Trainer for MoE ---\n",
    "    moe_csv_logger = CSVLogger(save_dir=MOE_LOGS_DIR, name=\"moe_rand_augment_run\") # Updated run name\n",
    "    \n",
    "    moe_loss_ckpt_cb = ModelCheckpoint(\n",
    "        dirpath=MOE_CHECKPOINT_SAVE_DIR, \n",
    "        filename='moe-best-loss-{epoch:02d}-{val_moe_loss:.3f}',\n",
    "        save_top_k=1, verbose=True, monitor='val_moe_loss', mode='min'\n",
    "    )\n",
    "    moe_iou_ckpt_cb = ModelCheckpoint(\n",
    "        dirpath=MOE_CHECKPOINT_SAVE_DIR, \n",
    "        filename='moe-best-iou-cereal-{epoch:02d}-{val_moe_jaccard_index_per_class_cereal:.3f}',\n",
    "        save_top_k=1, verbose=True, monitor='val_moe_jaccard_index_per_class_cereal', mode='max'\n",
    "    )\n",
    "    moe_early_stop_cb = EarlyStopping(\n",
    "        monitor=\"val_moe_loss\", patience=10, verbose=True, mode=\"min\"\n",
    "    )\n",
    "\n",
    "    is_interactive_moe = False\n",
    "    try: shell = get_ipython().__class__.__name__\n",
    "    except NameError: is_interactive_moe = False\n",
    "    else: \n",
    "        if shell == 'ZMQInteractiveShell': is_interactive_moe = True\n",
    "    \n",
    "    moe_strategy = \"auto\"\n",
    "    if DEVICE == \"cuda\" and torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        moe_strategy = \"ddp_notebook\" if is_interactive_moe else \"ddp_find_unused_parameters_true\"\n",
    "        print(f\"INFO (MoE): Multiple GPUs detected. Using '{moe_strategy}' strategy.\")\n",
    "    else:\n",
    "        print(f\"INFO (MoE): Single GPU or CPU. Using '{moe_strategy}' strategy.\")\n",
    "\n",
    "    moe_trainer = Trainer(\n",
    "        accelerator=DEVICE, devices=\"auto\" if DEVICE == \"cuda\" else 1,\n",
    "        strategy=moe_strategy, max_epochs=MOE_EPOCHS,\n",
    "        logger=moe_csv_logger,\n",
    "        callbacks=[moe_early_stop_cb, moe_loss_ckpt_cb, moe_iou_ckpt_cb],\n",
    "        gradient_clip_val=0.5,\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Starting MoE Training ---\")\n",
    "    try:\n",
    "        val_dl_arg_moe = moe_val_loader if moe_val_loader and hasattr(moe_val_loader, 'dataset') and len(moe_val_loader.dataset) > 0 else None\n",
    "        if not val_dl_arg_moe:\n",
    "            print(\"WARNING (MoE): Validation data not available. Adjusting callbacks that monitor validation metrics.\")\n",
    "            active_cbs = []\n",
    "            for cb_instance in moe_trainer.callbacks:\n",
    "                monitor_attr = getattr(cb_instance, 'monitor', None)\n",
    "                if monitor_attr and monitor_attr.startswith(\"val_moe_\"):\n",
    "                    print(f\"  INFO (MoE): Removing callback: {cb_instance.__class__.__name__} monitoring {monitor_attr}\")\n",
    "                else:\n",
    "                    active_cbs.append(cb_instance)\n",
    "            moe_trainer.callbacks = active_cbs if active_cbs else None\n",
    "\n",
    "        moe_trainer.fit(moe_lightning_system, \n",
    "                        train_dataloaders=moe_train_loader, \n",
    "                        val_dataloaders=val_dl_arg_moe)\n",
    "        print(\"MoE Training finished.\")\n",
    "        if hasattr(moe_loss_ckpt_cb, 'best_model_path') and moe_loss_ckpt_cb.best_model_path:\n",
    "            print(f\"Best MoE model (by loss) saved at: {moe_loss_ckpt_cb.best_model_path}\")\n",
    "        if hasattr(moe_iou_ckpt_cb, 'best_model_path') and moe_iou_ckpt_cb.best_model_path:\n",
    "            print(f\"Best MoE model (by IoU for cereal) saved at: {moe_iou_ckpt_cb.best_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during MoE training: {e}\")\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
