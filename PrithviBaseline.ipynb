{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6c3f6-935c-420b-9413-94649949f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, JaccardIndex\n",
    "from torchmetrics.collections import MetricCollection\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from terratorch.tasks import SemanticSegmentationTask\n",
    "import rasterio\n",
    "import glob\n",
    "import re\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "\n",
    "# Configuration\n",
    "BASE_DATA_DIR_ACTUAL = \"CerealDataset\"\n",
    "CHECKPOINT_SAVE_DIR_ACTUAL = \"checkpoints_baseline\"\n",
    "LOGS_DIR_ACTUAL = \"logs_baseline\"\n",
    "\n",
    "PATCHES_DIR = f\"{BASE_DATA_DIR_ACTUAL}/GEE_WeeklyPatches\"\n",
    "TARGETS_DIR = f\"{BASE_DATA_DIR_ACTUAL}/GEE_WeeklyMasks\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_SAVE_DIR_ACTUAL, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR_ACTUAL, exist_ok=True)\n",
    "\n",
    "print(f\"Data will be loaded from: {BASE_DATA_DIR_ACTUAL}\")\n",
    "print(f\"Checkpoints will be saved to: {CHECKPOINT_SAVE_DIR_ACTUAL}\")\n",
    "print(f\"CSV Logs will be saved to: {LOGS_DIR_ACTUAL}\")\n",
    "\n",
    "if not os.path.isdir(PATCHES_DIR):\n",
    "    print(f\"WARNING: Patches directory not found at {PATCHES_DIR}\")\n",
    "if not os.path.isdir(TARGETS_DIR):\n",
    "    print(f\"WARNING: Masks directory not found at {TARGETS_DIR}\")\n",
    "\n",
    "EXPECTED_BANDS_ORDER = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\"]\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = 256\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "LR = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "HEAD_DROPOUT = 0.2\n",
    "FREEZE_BACKBONE = False\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "EARLY_STOPPING_MONITOR = \"val_loss\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"PyTorch available: {torch.cuda.is_available()} (CUDA)\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"CUDA available: {torch.cuda.device_count()} device(s).\")\n",
    "\n",
    "\n",
    "# Dataset Definition\n",
    "class CerealSensingDataset(Dataset):\n",
    "    def __init__(self, file_identifiers, patches_dir, targets_dir, target_img_size):\n",
    "        self.file_identifiers = file_identifiers\n",
    "        self.patches_dir = patches_dir\n",
    "        self.targets_dir = targets_dir\n",
    "        self.target_img_size = target_img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_identifiers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        identifier = self.file_identifiers[idx]\n",
    "        image_filename = f\"{identifier}_S2.tif\"\n",
    "        mask_filename = f\"{identifier}_Mask.tif\"\n",
    "        image_path = os.path.join(self.patches_dir, image_filename)\n",
    "        label_path = os.path.join(self.targets_dir, mask_filename)\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                image = src.read()\n",
    "                if image.shape[0] != 6:\n",
    "                    raise ValueError(f\"Image {identifier} has {image.shape[0]} bands, expected 6.\")\n",
    "\n",
    "            with rasterio.open(label_path) as src:\n",
    "                label = src.read(1)\n",
    "\n",
    "            image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "            image_tensor = F.interpolate(\n",
    "                image_tensor.unsqueeze(0),\n",
    "                size=(self.target_img_size, self.target_img_size),\n",
    "                mode='bilinear', align_corners=False\n",
    "            ).squeeze(0)\n",
    "\n",
    "            label_tensor = F.interpolate(\n",
    "                label_tensor.unsqueeze(0).unsqueeze(0),\n",
    "                size=(self.target_img_size, self.target_img_size),\n",
    "                mode='nearest'\n",
    "            ).squeeze(0).squeeze(0)\n",
    "\n",
    "            label_tensor = label_tensor.long()\n",
    "\n",
    "            if image_tensor.shape != (6, self.target_img_size, self.target_img_size) or \\\n",
    "               label_tensor.shape != (self.target_img_size, self.target_img_size):\n",
    "                raise ValueError(f\"Shape mismatch for {identifier}\")\n",
    "\n",
    "            return image_tensor, label_tensor\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading/processing {identifier}: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "# Data loading, integrity check, splitting\n",
    "print(\"\\n=========== Data Loading & Prep ============\")\n",
    "image_files_pattern = os.path.join(PATCHES_DIR, \"Patch*_S2.tif\")\n",
    "all_image_filepaths = sorted(glob.glob(image_files_pattern))\n",
    "\n",
    "initial_file_identifiers = []\n",
    "if not all_image_filepaths:\n",
    "    print(f\"ERROR: No image files found in {PATCHES_DIR}\")\n",
    "else:\n",
    "    print(f\"Found {len(all_image_filepaths)} potential images. Checking masks...\")\n",
    "\n",
    "for img_path in all_image_filepaths:\n",
    "    base_name = os.path.basename(img_path)\n",
    "    identifier_match = re.match(r\"(Patch\\d+_W\\d+_\\d{8})_S2\\.tif\", base_name)\n",
    "\n",
    "    if identifier_match:\n",
    "        identifier = identifier_match.group(1)\n",
    "        mask_path = os.path.join(TARGETS_DIR, f\"{identifier}_Mask.tif\")\n",
    "        if os.path.exists(mask_path):\n",
    "            initial_file_identifiers.append(identifier)\n",
    "        else:\n",
    "            print(f\"WARNING: Missing mask for {identifier}\")\n",
    "    else:\n",
    "        print(f\"WARNING: Could not parse {base_name}\")\n",
    "\n",
    "print(f\"Found {len(initial_file_identifiers)} initial pairs.\")\n",
    "\n",
    "print(f\"\\nPerforming data integrity check on {len(initial_file_identifiers)} samples...\")\n",
    "corrupted_identifiers = []\n",
    "valid_identifiers = []\n",
    "\n",
    "for identifier in initial_file_identifiers:\n",
    "    image_path = os.path.join(PATCHES_DIR, f\"{identifier}_S2.tif\")\n",
    "    try:\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image_data = src.read()\n",
    "\n",
    "        problem = False\n",
    "        msgs = []\n",
    "\n",
    "        if np.isnan(image_data).any():\n",
    "            msgs.append(\"NaNs\")\n",
    "            problem = True\n",
    "\n",
    "        if np.any(image_data > 30000) or np.any(image_data < 0):\n",
    "            msgs.append(\"Extreme values\")\n",
    "            problem = True\n",
    "\n",
    "        if image_data.size > 0:\n",
    "            is_uniform = np.allclose(image_data, image_data[0, 0, 0], atol=1e-5)\n",
    "            if is_uniform:\n",
    "                msgs.append(\"Uniform\")\n",
    "                problem = True\n",
    "\n",
    "        if problem:\n",
    "            print(f\"WARNING: {identifier}: {msgs}\")\n",
    "            corrupted_identifiers.append(identifier)\n",
    "        else:\n",
    "            valid_identifiers.append(identifier)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR checking {identifier}: {e}\")\n",
    "        corrupted_identifiers.append(identifier)\n",
    "\n",
    "print(f\"Integrity check complete. Corrupted: {len(corrupted_identifiers)}\")\n",
    "clean_identifiers = valid_identifiers\n",
    "num_clean_patches = len(clean_identifiers)\n",
    "print(f\"Clean patches: {num_clean_patches}\")\n",
    "\n",
    "train_ds, val_ds, train_loader, val_loader = None, None, None, None\n",
    "\n",
    "if num_clean_patches > 0:\n",
    "    random.shuffle(clean_identifiers)\n",
    "\n",
    "    if num_clean_patches >= 2:\n",
    "        num_train = max(1, int(num_clean_patches * 0.8))\n",
    "        train_ids = clean_identifiers[:num_train]\n",
    "        val_ids = clean_identifiers[num_train:]\n",
    "        if len(val_ids) == 0:\n",
    "            val_ids = [train_ids.pop()]\n",
    "    elif num_clean_patches == 1:\n",
    "        train_ids = clean_identifiers\n",
    "        val_ids = []\n",
    "    else:\n",
    "        train_ids = []\n",
    "        val_ids = []\n",
    "\n",
    "    print(f\"Training IDs: {len(train_ids)}, Validation IDs: {len(val_ids)}\")\n",
    "\n",
    "    if train_ids:\n",
    "        train_ds = CerealSensingDataset(train_ids, PATCHES_DIR, TARGETS_DIR, IMG_SIZE)\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    if val_ids:\n",
    "        val_ds = CerealSensingDataset(val_ids, PATCHES_DIR, TARGETS_DIR, IMG_SIZE)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "else:\n",
    "    print(\"ERROR: No clean patches available.\")\n",
    "\n",
    "# Model Setup with TerraTorch\n",
    "print(\"\\n=========== Model Setup ============\")\n",
    "model_args = {\n",
    "    \"backbone\": \"prithvi_eo_v2_300\",\n",
    "    \"backbone_pretrained\": True,\n",
    "    \"backbone_bands\": EXPECTED_BANDS_ORDER,\n",
    "    \"decoder\": \"FCNDecoder\",\n",
    "    \"decoder_channels\": 256,\n",
    "    \"head_dropout\": HEAD_DROPOUT,\n",
    "    \"num_classes\": NUM_CLASSES,\n",
    "    \"rescale\": True\n",
    "}\n",
    "\n",
    "task_config_obj = SemanticSegmentationTask(\n",
    "    model_args=model_args,\n",
    "    model_factory=\"EncoderDecoderFactory\",\n",
    "    loss=\"ce\",\n",
    "    freeze_backbone=FREEZE_BACKBONE,\n",
    "    lr=LR,\n",
    "    optimizer=\"adamw\",\n",
    "    optimizer_hparams={\"weight_decay\": WEIGHT_DECAY}\n",
    ")\n",
    "\n",
    "print(f\"Backbone freezing: {FREEZE_BACKBONE}\")\n",
    "\n",
    "\n",
    "# Lightning Module\n",
    "class LitSegmentationModel(LightningModule):\n",
    "    def __init__(self, model_arch, learning_rate, weight_decay, num_classes, class_names=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model_arch'])\n",
    "        self.model = model_arch\n",
    "        self.class_weights_tensor = None\n",
    "        self.class_names = class_names if class_names else [f\"class{i}\" for i in range(num_classes)]\n",
    "\n",
    "        metrics = MetricCollection({\n",
    "            'accuracy_overall': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='micro'),\n",
    "            'precision_macro': Precision(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'recall_macro': Recall(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'f1_score_macro': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro'),\n",
    "            'jaccard_index_per_class': JaccardIndex(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'accuracy_per_class': Accuracy(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'precision_per_class': Precision(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'recall_per_class': Recall(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "            'f1_score_per_class': F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='none'),\n",
    "        })\n",
    "\n",
    "        self.val_metrics = metrics.clone(prefix='val_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out_struct = self.model(x)\n",
    "        logits = out_struct.output\n",
    "        weights = self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(logits, y, weight=weights)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out_struct = self.model(x)\n",
    "        logits = out_struct.output\n",
    "        weights = self.class_weights_tensor.to(logits.device) if self.class_weights_tensor is not None else None\n",
    "        loss = F.cross_entropy(logits, y, weight=weights)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "\n",
    "        preds_classes = torch.argmax(logits, dim=1)\n",
    "        self.val_metrics.update(preds_classes, y)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics_output = self.val_metrics.compute()\n",
    "\n",
    "        for name, value in metrics_output.items():\n",
    "            log_to_prog_bar = name in [\"val_accuracy_overall\", \"val_f1_score_macro\"]\n",
    "\n",
    "            if isinstance(value, torch.Tensor) and value.numel() == self.hparams.num_classes:\n",
    "                for i in range(self.hparams.num_classes):\n",
    "                    class_metric_name = f\"{name}_{self.class_names[i]}\"\n",
    "                    self.log(class_metric_name, value[i], prog_bar=False, logger=True, on_step=False, on_epoch=True, sync_dist=True)\n",
    "\n",
    "                    if self.class_names[i] == \"cereal\":\n",
    "                        if name == \"val_jaccard_index_per_class\":\n",
    "                            self.log(\"val_iou_cereal\", value[i], prog_bar=True, logger=False, on_epoch=True, sync_dist=True)\n",
    "                        elif name == \"val_f1_score_per_class\":\n",
    "                            self.log(\"val_f1_cereal\", value[i], prog_bar=True, logger=False, on_epoch=True, sync_dist=True)\n",
    "            else:\n",
    "                self.log(name, value, prog_bar=log_to_prog_bar, logger=True, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "\n",
    "\n",
    "CLASS_NAMES_FOR_LOGGING = [\"non_cereal\", \"cereal\"]\n",
    "lightning_model = None\n",
    "\n",
    "if 'task_config_obj' in locals() or 'task_config_obj' in globals():\n",
    "    lightning_model = LitSegmentationModel(\n",
    "        model_arch=task_config_obj.model,\n",
    "        learning_rate=LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        class_names=CLASS_NAMES_FOR_LOGGING\n",
    "    )\n",
    "    print(\"LitSegmentationModel instantiated.\")\n",
    "else:\n",
    "    print(\"ERROR: task_config_obj not defined.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
